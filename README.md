# ğŸŒŸ My Awesome AI Stars

> ğŸ¤– è‡ªåŠ¨ç”Ÿæˆäº GitHub Actions, Powered by LLM.

## ç›®å½•
- [AI-Sys-Train (è®­ç»ƒæ¡†æ¶, DeepSpeed, Megatron) (28)](#ai-sys-train)
- [AI-Sys-Inference (æ¨ç†ä¸éƒ¨ç½², vLLM, TGI) (12)](#ai-sys-inference)
- [AI-Sys-Perf (æ€§èƒ½ä¼˜åŒ–, CUDA, Kernel) (7)](#ai-sys-perf)
- [AI-Sys-Core (DLæ¡†æ¶åº•åº§, PyTorch, JAX) (4)](#ai-sys-core)
- [AI-Algo-Model (æ¨¡å‹æ¶æ„, Llama, Qwen) (14)](#ai-algo-model)
- [AI-App-Agent (Agent, CoT, Planner) (24)](#ai-app-agent)
- [AI-App-Utils (LangChain, RAG, PDFè§£æ) (3)](#ai-app-utils)
- [AI-Data (æ•°æ®é›†, æ•°æ®å¤„ç†) (2)](#ai-data)
- [Dev-Web (å‰åç«¯å¼€å‘) (4)](#dev-web)
- [Tools-CLI (å‘½ä»¤è¡Œå·¥å…·, æ•ˆç‡è„šæœ¬) (5)](#tools-cli)
- [Research-Other (å…¶ä»–ç ”ç©¶, é‡åŒ–ç­‰) (3)](#research-other)
- [Uncategorized (æ— æ³•åˆ†ç±») (3)](#uncategorized)
- [Algo-DS-Notes (ç®—æ³•ä¸æ•°æ®ç»“æ„å­¦ä¹ ç¬”è®°) (1)](#algo-ds-notes)

---
## <span id='ai-sys-train'>AI-Sys-Train (è®­ç»ƒæ¡†æ¶, DeepSpeed, Megatron)</span>

| Project | Description | Stars | Language |
|---|---|---|---|
| [unslothai/unsloth](https://github.com/unslothai/unsloth) | Fine-tuning & Reinforcement Learning for LLMs. ğŸ¦¥ Train OpenAI gpt-oss, DeepSeek, Qwen, Llama, Gemma, TTS 2x faster with 70% less VRAM. | 50137 | Python |
| [jingyaogong/minimind](https://github.com/jingyaogong/minimind) | ğŸš€ğŸš€ ã€Œå¤§æ¨¡å‹ã€2å°æ—¶å®Œå…¨ä»0è®­ç»ƒ26Mçš„å°å‚æ•°GPTï¼ğŸŒ Train a 26M-parameter GPT from scratch in just 2h! | 36393 | Python |
| [liguodongiot/llm-action](https://github.com/liguodongiot/llm-action) | æœ¬é¡¹ç›®æ—¨åœ¨åˆ†äº«å¤§æ¨¡å‹ç›¸å…³æŠ€æœ¯åŸç†ä»¥åŠå®æˆ˜ç»éªŒï¼ˆå¤§æ¨¡å‹å·¥ç¨‹åŒ–ã€å¤§æ¨¡å‹åº”ç”¨è½åœ°ï¼‰ | 22584 | HTML |
| [volcengine/verl](https://github.com/volcengine/verl) | verl: Volcano Engine Reinforcement Learning for LLMs | 17937 | Python |
| [NVIDIA/Megatron-LM](https://github.com/NVIDIA/Megatron-LM) | Ongoing research training transformer models at scale | 14766 | Python |
| [OpenRLHF/OpenRLHF](https://github.com/OpenRLHF/OpenRLHF) | An Easy-to-use, Scalable and High-performance RLHF Framework based on Ray (PPO & GRPO & REINFORCE++ & TIS & vLLM & Ray & Dynamic Sampling & Async Agentic RL) | 8684 | Python |
| [pytorch/torchtitan](https://github.com/pytorch/torchtitan) | A PyTorch native platform for training generative AI models | 4898 | Python |
| [zhaochenyang20/Awesome-ML-SYS-Tutorial](https://github.com/zhaochenyang20/Awesome-ML-SYS-Tutorial) | My learning notes for ML SYS. | 4849 | Python |
| [PKU-Alignment/align-anything](https://github.com/PKU-Alignment/align-anything) | Align Anything: Training All-modality Model with Feedback | 4615 | Python |
| [hiyouga/EasyR1](https://github.com/hiyouga/EasyR1) | EasyR1: An Efficient, Scalable, Multi-Modality RL Training Framework based on veRL | 4351 | Python |
| [THUDM/slime](https://github.com/THUDM/slime) | slime is an LLM post-training framework for RL Scaling. | 3077 | Python |
| [alibaba/ROLL](https://github.com/alibaba/ROLL) | An Efficient and User-Friendly Scaling Library for Reinforcement Learning with Large Language Models | 2549 | Python |
| [qibin0506/Cortex](https://github.com/qibin0506/Cortex) | ä¸ªäººæ„å»ºMoEå¤§æ¨¡å‹ï¼šä»é¢„è®­ç»ƒåˆ°DPOçš„å®Œæ•´å®è·µ | 2155 | Python |
| [adonis-dym/memory_reduced_optimizer](https://github.com/adonis-dym/memory_reduced_optimizer) |  | 530 | Python |
| [Victorwz/Open-Qwen2VL](https://github.com/Victorwz/Open-Qwen2VL) | [COLM 2025] Open-Qwen2VL: Compute-Efficient Pre-Training of Fully-Open Multimodal LLMs on Academic Resources | 297 | Python |
| [liangyuwang/zo2](https://github.com/liangyuwang/zo2) | ZO2 (Zeroth-Order Offloading): Full Parameter Fine-Tuning 175B LLMs with 18GB GPU Memory [COLM2025] | 198 | Python |
| [MiroMindAI/MiroTrain](https://github.com/MiroMindAI/MiroTrain) | MiroTrain is an efficient and algorithm-first framework for post-training large agentic models.  | 99 | Python |
| [CoinCheung/gdGPT](https://github.com/CoinCheung/gdGPT) | Train llm (bloom, llama, baichuan2-7b, chatglm3-6b) with deepspeed pipeline mode. Faster than zero/zero++/fsdp. | 98 | Python |
| [liangyuwang/Tiny-FSDP](https://github.com/liangyuwang/Tiny-FSDP) | Tiny-FSDP, a minimalistic re-implementation of the PyTorch FSDP | 93 | Python |
| [AI-Study-Han/Zero-Qwen-VL](https://github.com/AI-Study-Han/Zero-Qwen-VL) | è®­ç»ƒä¸€ä¸ªå¯¹ä¸­æ–‡æ”¯æŒæ›´å¥½çš„LLaVAæ¨¡å‹ï¼Œå¹¶å¼€æºè®­ç»ƒä»£ç å’Œæ•°æ®ã€‚ | 77 | Python |
| [nex-agi/NexRL](https://github.com/nex-agi/NexRL) | NexRL is an ultra-loosely-coupled LLM post-training framework. | 62 | Python |
| [liangyuwang/Tiny-DeepSpeed](https://github.com/liangyuwang/Tiny-DeepSpeed) | Tiny-DeepSpeed, a minimalistic re-implementation of the DeepSpeed library | 49 | Python |
| [0x0C001/OpenSFT](https://github.com/0x0C001/OpenSFT) |  | 46 | Python |
| [qibin0506/llm_trainer](https://github.com/qibin0506/llm_trainer) |  | 43 | Python |
| [0x0C001/OpenDPO](https://github.com/0x0C001/OpenDPO) |  | 33 | Python |
| [XU-YIJIE/hobo-llm-from-scratch](https://github.com/XU-YIJIE/hobo-llm-from-scratch) | From Llama to Deepseek, grpo/mtp implemented. With pt/sft/lora/qlora included | 30 | Python |
| [liangyuwang/Tiny-Megatron](https://github.com/liangyuwang/Tiny-Megatron) | Tiny-Megatron, a minimalistic re-implementation of the Megatron library | 21 | Python |
| [liangyuwang/Streaming-Dataloader](https://github.com/liangyuwang/Streaming-Dataloader) |  A memory-efficient streaming data loader designed for LLM pretraining under limited CPU and GPU memory constraints | 3 | Python |

## <span id='ai-sys-inference'>AI-Sys-Inference (æ¨ç†ä¸éƒ¨ç½², vLLM, TGI)</span>

| Project | Description | Stars | Language |
|---|---|---|---|
| [ollama/ollama](https://github.com/ollama/ollama) | Get up and running with OpenAI gpt-oss, DeepSeek-R1, Gemma 3 and other models. | 158537 | Go |
| [comfyanonymous/ComfyUI](https://github.com/comfyanonymous/ComfyUI) | The most powerful and modular diffusion model GUI, api and backend with a graph/nodes interface. | 98612 | Python |
| [ggml-org/llama.cpp](https://github.com/ggml-org/llama.cpp) | LLM inference in C/C++ | 92251 | C++ |
| [vllm-project/vllm](https://github.com/vllm-project/vllm) | A high-throughput and memory-efficient inference and serving engine for LLMs | 66584 | Python |
| [sgl-project/sglang](https://github.com/sgl-project/sglang) | SGLang is a high-performance serving framework for large language models and multimodal models. | 22094 | Python |
| [GeeeekExplorer/nano-vllm](https://github.com/GeeeekExplorer/nano-vllm) | Nano vLLM | 10408 | Python |
| [QuentinFuxa/WhisperLiveKit](https://github.com/QuentinFuxa/WhisperLiveKit) | Simultaneous speech-to-text model | 9372 | Python |
| [jt-zhang/Sparse_Attention_API](https://github.com/jt-zhang/Sparse_Attention_API) |  | 65 | Python |
| [difey/nano-vllm-v1](https://github.com/difey/nano-vllm-v1) | Nano vLLM v1 engine | 12 | N/A |
| [cosmoliu2002/nano-vllm-triton](https://github.com/cosmoliu2002/nano-vllm-triton) | Nano vLLM Triton | 11 | Python |
| [RealJosephus/radix-turn-aware-nano-vllm](https://github.com/RealJosephus/radix-turn-aware-nano-vllm) | Radix Tree KV Cache with Turn-Aware Growth | 8 | Python |
| [liangyuwang/Tiny-transformers](https://github.com/liangyuwang/Tiny-transformers) |  | 3 | Python |

## <span id='ai-sys-perf'>AI-Sys-Perf (æ€§èƒ½ä¼˜åŒ–, CUDA, Kernel)</span>

| Project | Description | Stars | Language |
|---|---|---|---|
| [deepseek-ai/FlashMLA](https://github.com/deepseek-ai/FlashMLA) | FlashMLA: Efficient Multi-head Latent Attention Kernels | 11946 | C++ |
| [facebookresearch/xformers](https://github.com/facebookresearch/xformers) | Hackable and optimized Transformers building blocks, supporting a composable construction. | 10238 | Python |
| [linkedin/Liger-Kernel](https://github.com/linkedin/Liger-Kernel) | Efficient Triton Kernels for LLM Training | 5994 | Python |
| [KellerJordan/modded-nanogpt](https://github.com/KellerJordan/modded-nanogpt) | NanoGPT (124M) in 3 minutes | 4062 | Python |
| [IST-DASLab/marlin](https://github.com/IST-DASLab/marlin) | FP16xINT4 LLM inference kernel that can achieve near-ideal ~4x speedups up to medium batchsizes of 16-32 tokens. | 973 | Python |
| [DefTruth/CUDA-Learn-Notes](https://github.com/DefTruth/CUDA-Learn-Notes) | ğŸ“š200+ Tensor/CUDA Cores Kernels, âš¡ï¸flash-attn-mma, âš¡ï¸hgemm with WMMA, MMA and CuTe (98%~100% TFLOPS of cuBLAS/FA2 ğŸ‰ğŸ‰). | 57 | Cuda |
| [liangyuwang/MetaProfiler](https://github.com/liangyuwang/MetaProfiler) | MetaProfiler is a lightweight, structure-agnostic operator-level profiler for PyTorch models that leverages MetaTensor execution to simulate and benchmark individual ops without loading the full model into GPU memory. | 2 | Python |

## <span id='ai-sys-core'>AI-Sys-Core (DLæ¡†æ¶åº•åº§, PyTorch, JAX)</span>

| Project | Description | Stars | Language |
|---|---|---|---|
| [huggingface/transformers](https://github.com/huggingface/transformers) | ğŸ¤— Transformers: the model-definition framework for state-of-the-art machine learning models in text, vision, audio, and multimodal models, for both inference and training.  | 154439 | Python |
| [pytorch/pytorch](https://github.com/pytorch/pytorch) | Tensors and Dynamic neural networks in Python with strong GPU acceleration | 96251 | Python |
| [ray-project/ray](https://github.com/ray-project/ray) | Ray is an AI compute engine. Ray consists of a core distributed runtime and a set of AI Libraries for accelerating ML workloads. | 40556 | Python |
| [tigert1998/mytorch](https://github.com/tigert1998/mytorch) | A toy Python DL training library with PyTorch like API | 38 | Python |

## <span id='ai-algo-model'>AI-Algo-Model (æ¨¡å‹æ¶æ„, Llama, Qwen)</span>

| Project | Description | Stars | Language |
|---|---|---|---|
| [QwenLM/Qwen3-VL](https://github.com/QwenLM/Qwen3-VL) | Qwen3-VL is the multimodal large language model series developed by Qwen team, Alibaba Cloud. | 17491 | Jupyter Notebook |
| [wgwang/awesome-LLMs-In-China](https://github.com/wgwang/awesome-LLMs-In-China) | ä¸­å›½å¤§æ¨¡å‹ | 6348 | N/A |
| [om-ai-lab/VLM-R1](https://github.com/om-ai-lab/VLM-R1) | Solve Visual Understanding with Reinforced VLMs | 5783 | Python |
| [imoneoi/openchat](https://github.com/imoneoi/openchat) | OpenChat: Advancing Open-source Language Models with Imperfect Data | 5465 | Python |
| [NVlabs/Sana](https://github.com/NVlabs/Sana) | SANA: Efficient High-Resolution Image Synthesis with Linear Diffusion Transformer | 4858 | Python |
| [wyf3/llm_related](https://github.com/wyf3/llm_related) | å¤ç°å¤§æ¨¡å‹ç›¸å…³ç®—æ³•åŠä¸€äº›å­¦ä¹ è®°å½• | 2774 | Python |
| [Open-Reasoner-Zero/Open-Reasoner-Zero](https://github.com/Open-Reasoner-Zero/Open-Reasoner-Zero) | Official Repo for Open-Reasoner-Zero | 2085 | Python |
| [Duxiaoman-DI/XuanYuan](https://github.com/Duxiaoman-DI/XuanYuan) | è½©è¾•ï¼šåº¦å°æ»¡ä¸­æ–‡é‡‘èå¯¹è¯å¤§æ¨¡å‹ | 1287 | Python |
| [MoonshotAI/Kimi-VL](https://github.com/MoonshotAI/Kimi-VL) | Kimi-VL: Mixture-of-Experts Vision-Language Model for Multimodal Reasoning, Long-Context Understanding, and Strong Agent Capabilities | 1134 | N/A |
| [wdndev/llama3-from-scratch-zh](https://github.com/wdndev/llama3-from-scratch-zh) | ä»é›¶å®ç°ä¸€ä¸ª llama3 ä¸­æ–‡ç‰ˆ | 1000 | Jupyter Notebook |
| [wdndev/tiny-llm-zh](https://github.com/wdndev/tiny-llm-zh) | ä»é›¶å®ç°ä¸€ä¸ªå°å‚æ•°é‡ä¸­æ–‡å¤§è¯­è¨€æ¨¡å‹ã€‚ | 916 | Python |
| [hkproj/pytorch-paligemma](https://github.com/hkproj/pytorch-paligemma) | Coding a Multimodal (Vision) Language Model from scratch in PyTorch with full explanation: https://www.youtube.com/watch?v=vAmKB7iPkWw | 579 | Python |
| [forXuyx/Cinego](https://github.com/forXuyx/Cinego) | ğŸš€ è½»é‡è§†é¢‘ğŸ¥ å¤§æ¨¡å‹ğŸ¤– | 20 | Python |
| [Layjins/Spider](https://github.com/Layjins/Spider) | Code for paper "Spider: Any-to-Many Multimodal LLM" | 14 | Python |

## <span id='ai-app-agent'>AI-App-Agent (Agent, CoT, Planner)</span>

| Project | Description | Stars | Language |
|---|---|---|---|
| [x1xhlol/system-prompts-and-models-of-ai-tools](https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools) | FULL Augment Code, Claude Code, Cluely, CodeBuddy, Comet, Cursor, Devin AI, Junie, Kiro, Leap.new, Lovable, Manus, NotionAI, Orchids.app, Perplexity, Poke, Qoder, Replit, Same.dev, Trae, Traycer AI, VSCode Agent, Warp.dev, Windsurf, Xcode, Z.ai Code, Dia & v0. (And other Open Sourced) System Prompts, Internal Tools & AI Models | 104334 | N/A |
| [lobehub/lobe-chat](https://github.com/lobehub/lobe-chat) | ğŸ¤¯ LobeHub - an open-source, modern design AI Agent Workspace. Supports multiple AI providers, Knowledge Base (file upload / RAG ), one click install MCP Marketplace and Artifacts / Thinking. One-click FREE deployment of your private AI Agent application. | 69656 | TypeScript |
| [karpathy/nanochat](https://github.com/karpathy/nanochat) | The best ChatGPT that $100 can buy. | 39531 | Python |
| [danielmiessler/Fabric](https://github.com/danielmiessler/Fabric) | Fabric is an open-source framework for augmenting humans using AI. It provides a modular system for solving specific problems using a crowdsourced set of AI prompts that can be used anywhere. | 37432 | Go |
| [chatchat-space/Langchain-Chatchat](https://github.com/chatchat-space/Langchain-Chatchat) | Langchain-Chatchatï¼ˆåŸLangchain-ChatGLMï¼‰åŸºäº Langchain ä¸ ChatGLM, Qwen ä¸ Llama ç­‰è¯­è¨€æ¨¡å‹çš„ RAG ä¸ Agent åº”ç”¨ \| Langchain-Chatchat (formerly langchain-ChatGLM), local knowledge based LLM (like ChatGLM, Qwen and Llama) RAG and Agent app with langchain  | 36952 | Python |
| [666ghj/BettaFish](https://github.com/666ghj/BettaFish) | å¾®èˆ†ï¼šäººäººå¯ç”¨çš„å¤šAgentèˆ†æƒ…åˆ†æåŠ©æ‰‹ï¼Œæ‰“ç ´ä¿¡æ¯èŒ§æˆ¿ï¼Œè¿˜åŸèˆ†æƒ…åŸè²Œï¼Œé¢„æµ‹æœªæ¥èµ°å‘ï¼Œè¾…åŠ©å†³ç­–ï¼ä»0å®ç°ï¼Œä¸ä¾èµ–ä»»ä½•æ¡†æ¶ã€‚ | 33844 | Python |
| [continuedev/continue](https://github.com/continuedev/continue) | â© Ship faster with Continuous AI. Open-source CLI that can be used in TUI mode as a coding agent or Headless mode to run background agents | 30584 | TypeScript |
| [Alibaba-NLP/DeepResearch](https://github.com/Alibaba-NLP/DeepResearch) | Tongyi Deep Research, the Leading Open-source Deep Research Agent | 17790 | Python |
| [lfnovo/open-notebook](https://github.com/lfnovo/open-notebook) | An Open Source implementation of Notebook LM with more flexibility and features | 16944 | TypeScript |
| [DayuanJiang/next-ai-draw-io](https://github.com/DayuanJiang/next-ai-draw-io) | A next.js web application that integrates AI capabilities with draw.io diagrams. This app allows you to create, modify, and enhance diagrams through natural language commands and AI-assisted visualization. | 15858 | TypeScript |
| [datawhalechina/hello-agents](https://github.com/datawhalechina/hello-agents) | ğŸ“š ã€Šä»é›¶å¼€å§‹æ„å»ºæ™ºèƒ½ä½“ã€‹â€”â€”ä»é›¶å¼€å§‹çš„æ™ºèƒ½ä½“åŸç†ä¸å®è·µæ•™ç¨‹ | 13561 | Python |
| [dataelement/bisheng](https://github.com/dataelement/bisheng) | BISHENG is an open LLM devops platform for next generation Enterprise AI applications. Powerful and comprehensive features include: GenAI workflow, RAG, Agent, Unified model management, Evaluation, SFT, Dataset Management, Enterprise-level System Management, Observability and more. | 10831 | TypeScript |
| [xpzouying/xiaohongshu-mcp](https://github.com/xpzouying/xiaohongshu-mcp) | MCP for xiaohongshu.com | 7756 | Go |
| [idosal/git-mcp](https://github.com/idosal/git-mcp) | Put an end to code hallucinations! GitMCP is a free, open-source, remote MCP server for any GitHub project | 7294 | TypeScript |
| [WangRongsheng/awesome-LLM-resources](https://github.com/WangRongsheng/awesome-LLM-resources) | ğŸ§‘â€ğŸš€ å…¨ä¸–ç•Œæœ€å¥½çš„LLMèµ„æ–™æ€»ç»“ï¼ˆå¤šæ¨¡æ€ç”Ÿæˆã€Agentã€è¾…åŠ©ç¼–ç¨‹ã€AIå®¡ç¨¿ã€æ•°æ®å¤„ç†ã€æ¨¡å‹è®­ç»ƒã€æ¨¡å‹æ¨ç†ã€o1 æ¨¡å‹ã€MCPã€å°è¯­è¨€æ¨¡å‹ã€è§†è§‰è¯­è¨€æ¨¡å‹ï¼‰ \| Summary of the world's best LLM resources.  | 7142 | N/A |
| [inclusionAI/AReaL](https://github.com/inclusionAI/AReaL) | Lightning-Fast RL for LLM Reasoning and Agents. Made Simple & Flexible. | 3298 | Python |
| [agent-infra/sandbox](https://github.com/agent-infra/sandbox) | All-in-One Sandbox for AI Agents that combines Browser, Shell, File, MCP and VSCode Server in a single Docker container. | 1842 | Python |
| [MeetKai/functionary](https://github.com/MeetKai/functionary) | Chat language model that can use tools and interpret the results | 1590 | Python |
| [iFurySt/RedNote-MCP](https://github.com/iFurySt/RedNote-MCP) | ğŸš€MCP server for accessing RedNote(XiaoHongShu, xhs). | 934 | TypeScript |
| [study8677/antigravity-workspace-template](https://github.com/study8677/antigravity-workspace-template) | ğŸª The ultimate starter kit for Google Antigravity IDE. Optimized for Gemini 3 Agentic Workflows, "Deep Think" mode, and auto-configuring .cursorrules. | 384 | Python |
| [vibesurf-ai/VibeSurf](https://github.com/vibesurf-ai/VibeSurf) | A powerful browser assistant for vibe surfing ä¸€ä¸ªå¼€æºçš„AIæµè§ˆå™¨æ™ºèƒ½åŠ©æ‰‹ | 378 | Python |
| [MiroMindAI/MiroRL](https://github.com/MiroMindAI/MiroRL) | MiroRL is  an MCP-first reinforcement learning framework for deep research agent. | 185 | Python |
| [AI-QL/chat-ui](https://github.com/AI-QL/chat-ui) | Single-File AI Chatbot UI with Multimodal & MCP Support: An All-in-One HTML File for a Streamlined Chatbot Conversational Interface | 87 | HTML |
| [jswortz/antigravity-claude-skills](https://github.com/jswortz/antigravity-claude-skills) |  | 2 | Python |

## <span id='ai-app-utils'>AI-App-Utils (LangChain, RAG, PDFè§£æ)</span>

| Project | Description | Stars | Language |
|---|---|---|---|
| [tukuaiai/vibe-coding-cn](https://github.com/tukuaiai/vibe-coding-cn) | æˆ‘çš„å¼€å‘ç»éªŒ+æç¤ºè¯åº“=vibecodingå·¥ä½œç«™ï¼›My development experience + prompt dictionary = Vibecoding workstationï¼›× ×™×¡×™×•×Ÿ ×”×¤×™×ª×•×— ×©×œ×™ + ××™×œ×•×Ÿ ×¤×¨×•××¤×˜×™× = ×ª×—× ×ª ×¢×‘×•×“×” Vibecodingï¼›ç§ã®é–‹ç™ºçµŒé¨“ + ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¾æ›¸ = Vibecoding ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ï¼›ë‚˜ì˜ ê°œë°œ ê²½í—˜ + í”„ë¡¬í”„íŠ¸ ì‚¬ì „ = Vibecoding ì›Œí¬ìŠ¤í…Œì´ì…˜ï¼›Mon expÃ©rience de dÃ©veloppement + dictionnaire de prompts = station de travail Vibecodingï¼›Meine Entwicklungserfahru | 5657 | Python |
| [mangiucugna/json_repair](https://github.com/mangiucugna/json_repair) | A python module to repair invalid JSON from LLMs | 4254 | Python |
| [CoinCheung/pytorch-loss](https://github.com/CoinCheung/pytorch-loss) | label-smooth, amsoftmax, partial-fc, focal-loss, triplet-loss, lovasz-softmax. Maybe useful  | 2259 | Python |

## <span id='ai-data'>AI-Data (æ•°æ®é›†, æ•°æ®å¤„ç†)</span>

| Project | Description | Stars | Language |
|---|---|---|---|
| [awesomedata/awesome-public-datasets](https://github.com/awesomedata/awesome-public-datasets) | A topic-centric list of HQ open datasets. | 71838 | N/A |
| [cv-cat/Spider_XHS](https://github.com/cv-cat/Spider_XHS) | å°çº¢ä¹¦çˆ¬è™«æ•°æ®é‡‡é›†ï¼Œå°çº¢ä¹¦å…¨åŸŸè¿è¥è§£å†³æ–¹æ¡ˆ | 3910 | JavaScript |

## <span id='dev-web'>Dev-Web (å‰åç«¯å¼€å‘)</span>

| Project | Description | Stars | Language |
|---|---|---|---|
| [open-webui/open-webui](https://github.com/open-webui/open-webui) | User-friendly AI Interface (Supports Ollama, OpenAI API, ...) | 119354 | Svelte |
| [jnsahaj/tweakcn](https://github.com/jnsahaj/tweakcn) | A visual no-code theme editor for shadcn/ui components | 8737 | TypeScript |
| [gamosoft/NoteDiscovery](https://github.com/gamosoft/NoteDiscovery) | Your Self-Hosted Knowledge Base | 1932 | JavaScript |
| [OpenGithubs/github-daily-rank](https://github.com/OpenGithubs/github-daily-rank) | Githubå¼€æºé¡¹ç›®:æ¯å¤©ğŸ“ˆé£™å‡æ¦œ top10,æ¯å¤©æ—©ä¸Š8:30æ›´æ–° | 744 | N/A |

## <span id='tools-cli'>Tools-CLI (å‘½ä»¤è¡Œå·¥å…·, æ•ˆç‡è„šæœ¬)</span>

| Project | Description | Stars | Language |
|---|---|---|---|
| [NanmiCoder/MediaCrawler](https://github.com/NanmiCoder/MediaCrawler) | å°çº¢ä¹¦ç¬”è®° \| è¯„è®ºçˆ¬è™«ã€æŠ–éŸ³è§†é¢‘ \| è¯„è®ºçˆ¬è™«ã€å¿«æ‰‹è§†é¢‘ \| è¯„è®ºçˆ¬è™«ã€B ç«™è§†é¢‘ ï½œ è¯„è®ºçˆ¬è™«ã€å¾®åšå¸–å­ ï½œ è¯„è®ºçˆ¬è™«ã€ç™¾åº¦è´´å§å¸–å­ ï½œ ç™¾åº¦è´´å§è¯„è®ºå›å¤çˆ¬è™«  \| çŸ¥ä¹é—®ç­”æ–‡ç« ï½œè¯„è®ºçˆ¬è™« | 41300 | Python |
| [VERT-sh/VERT](https://github.com/VERT-sh/VERT) | The next-generation file converter. Open source, fully local* and free forever. | 12888 | Svelte |
| [dreammis/social-auto-upload](https://github.com/dreammis/social-auto-upload) | è‡ªåŠ¨åŒ–ä¸Šä¼ è§†é¢‘åˆ°ç¤¾äº¤åª’ä½“ï¼šæŠ–éŸ³ã€å°çº¢ä¹¦ã€è§†é¢‘å·ã€tiktokã€youtubeã€bilibili | 7861 | Python |
| [hezhizheng/go-wxpush](https://github.com/hezhizheng/go-wxpush) | æç®€ä¸”å…è´¹çš„å¾®ä¿¡æ¶ˆæ¯æ¨é€æœåŠ¡ (åŸºäºgolang) | 1077 | Go |
| [cwjcw/xhs_douyin_content](https://github.com/cwjcw/xhs_douyin_content) | è‡ªåŠ¨æŠ“å–æŠ–éŸ³å’Œå°çº¢ä¹¦åˆ›ä½œè€…ä¸­å¿ƒé‡Œçš„æ¯æ¡ç¬”è®°/è§†é¢‘çš„æ’­æ”¾ï¼Œå®Œæ’­ï¼Œç‚¹å‡»ï¼Œæ’­æ”¾æ—¶é•¿ï¼Œç‚¹èµï¼Œåˆ†äº«ï¼Œè¯„è®ºï¼Œæ”¶è—ï¼Œä¸»é¡µè®¿é—®ï¼Œç²‰ä¸å¢é‡ç­‰äº’åŠ¨æ•°æ® | 251 | Python |

## <span id='research-other'>Research-Other (å…¶ä»–ç ”ç©¶, é‡åŒ–ç­‰)</span>

| Project | Description | Stars | Language |
|---|---|---|---|
| [vnpy/vnpy](https://github.com/vnpy/vnpy) | åŸºäºPythonçš„å¼€æºé‡åŒ–äº¤æ˜“å¹³å°å¼€å‘æ¡†æ¶ | 35027 | Python |
| [shiyu-coder/Kronos](https://github.com/shiyu-coder/Kronos) | Kronos: A Foundation Model for the Language of Financial Markets | 9751 | Python |
| [hanfang/chatgpt-usage-taxonomies](https://github.com/hanfang/chatgpt-usage-taxonomies) | Taxonomies and classification prompts from the 'How People Use ChatGPT' research paper (NBER Working Paper No. 34255) | 2 | N/A |

## <span id='uncategorized'>Uncategorized (æ— æ³•åˆ†ç±»)</span>

| Project | Description | Stars | Language |
|---|---|---|---|
| [slime/slime](https://github.com/slime/slime) | The Superior Lisp Interaction Mode for Emacs | 2016 | Common Lisp |
| [ChenmienTan/RL2](https://github.com/ChenmienTan/RL2) |  | 974 | Python |
| [jokemon/antiPM-Workflow](https://github.com/jokemon/antiPM-Workflow) | A collection of Antigravity workflows for Product Managers. (äº§å“ç»ç†ä¸“å±çš„ Antigravity å·¥ä½œæµåˆé›†) | 11 | N/A |

## <span id='algo-ds-notes'>Algo-DS-Notes (ç®—æ³•ä¸æ•°æ®ç»“æ„å­¦ä¹ ç¬”è®°)</span>

| Project | Description | Stars | Language |
|---|---|---|---|
| [itcharge/AlgoNote](https://github.com/itcharge/AlgoNote) | â›½ï¸ã€Œç®—æ³•é€šå…³æ‰‹å†Œã€ï¼šä»é›¶å¼€å§‹çš„ã€Œç®—æ³•ä¸æ•°æ®ç»“æ„ã€å­¦ä¹ æ•™ç¨‹ï¼Œ200 é“ã€Œç®—æ³•é¢è¯•çƒ­é—¨é¢˜ç›®ã€ï¼Œ1000+ é“ã€ŒLeetCode é¢˜ç›®è§£æã€ï¼ŒæŒç»­æ›´æ–°ä¸­ï¼ | 7494 | Python |

