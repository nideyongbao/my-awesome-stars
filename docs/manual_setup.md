# æ‰‹åŠ¨éƒ¨ç½²æŒ‡å— (Project Setup)

ç”±äºåˆå§‹è‡ªåŠ¨åŒ–ä¸Šä¼ å¯èƒ½é‡åˆ°æƒé™é—®é¢˜ (Permission Denied)ï¼Œæœ¬æŒ‡å—è®°å½•äº†æ‰‹åŠ¨éƒ¨ç½²æœ¬ç³»ç»Ÿçš„å®Œæ•´æ­¥éª¤å’Œä»£ç ã€‚

## 1. æ ¸å¿ƒæ–‡ä»¶ç»“æ„
ä½ éœ€è¦ç¡®ä¿ä»“åº“æ ¹ç›®å½•ä¸‹åŒ…å«ä»¥ä¸‹æ–‡ä»¶ï¼š

```text
/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ update.yml    # GitHub Actions é…ç½®æ–‡ä»¶
â”œâ”€â”€ main.py               # æ ¸å¿ƒæ‰§è¡Œè„šæœ¬
â””â”€â”€ requirements.txt      # Python ä¾èµ–
```

## 2. æ–‡ä»¶å†…å®¹

### 2.1 `requirements.txt`
```plaintext
PyGithub
openai
tqdm
```

### 2.2 `main.py`
æ ¸å¿ƒé€»è¾‘ï¼šè·å– Star -> å¯¹æ¯”ç¼“å­˜ -> LLM åˆ†ç±» -> æ›´æ–° Markdownã€‚

```python
import os
import json
import time
from github import Github
from openai import OpenAI
from tqdm import tqdm

# --- é…ç½®éƒ¨åˆ† ---
GITHUB_TOKEN = os.getenv("GH_TOKEN")
LLM_API_KEY = os.getenv("LLM_API_KEY")
LLM_BASE_URL = os.getenv("LLM_BASE_URL", "https://api.deepseek.com") 
LLM_MODEL = os.getenv("LLM_MODEL", "deepseek-chat") 

# ä½ çš„åˆ†ç±»ä½“ç³»
CATEGORIES = [
    "AI-Sys-Train (è®­ç»ƒæ¡†æ¶, DeepSpeed, Megatron)",
    "AI-Sys-Inference (æ¨ç†ä¸éƒ¨ç½², vLLM, TGI)",
    "AI-Sys-Perf (æ€§èƒ½ä¼˜åŒ–, CUDA, Kernel)",
    "AI-Sys-Core (DLæ¡†æ¶åº•åº§, PyTorch, JAX)",
    "AI-Algo-Model (æ¨¡å‹æ¶æ„, Llama, Qwen)",
    "AI-App-Agent (Agent, CoT, Planner)",
    "AI-App-Utils (LangChain, RAG, PDFè§£æ)",
    "AI-Data (æ•°æ®é›†, æ•°æ®å¤„ç†)",
    "Dev-Web (å‰åç«¯å¼€å‘)",
    "Tools-CLI (å‘½ä»¤è¡Œå·¥å…·, æ•ˆç‡è„šæœ¬)",
    "Proj-RedLoop (RedLoopç›¸å…³é¡¹ç›®)",
    "Research-Other (å…¶ä»–ç ”ç©¶, é‡åŒ–ç­‰)",
    "Uncategorized (æ— æ³•åˆ†ç±»)"
]

CACHE_FILE = "stars_cache.json"

def get_llm_category(repo_name, description):
    """è°ƒç”¨ LLM è¿›è¡Œåˆ†ç±»"""
    client = OpenAI(api_key=LLM_API_KEY, base_url=LLM_BASE_URL)
    
    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯ä»“åº“åˆ†ç±»å™¨ã€‚è¯·æ ¹æ®ä»¥ä¸‹ GitHub ä»“åº“ä¿¡æ¯ï¼Œä»ç»™å®šçš„åˆ†ç±»åˆ—è¡¨ä¸­é€‰æ‹©æœ€åŒ¹é…çš„ä¸€ä¸ªã€‚
    
    ä»“åº“å: {repo_name}
    æè¿°: {description}
    
    å¯é€‰åˆ†ç±»åˆ—è¡¨:
    {json.dumps(CATEGORIES, ensure_ascii=False)}
    
    è§„åˆ™ï¼š
    1. åªèƒ½è¿”å›åˆ—è¡¨ä¸­çš„æŸä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œä¸è¦è§£é‡Šã€‚
    2. å¦‚æœæ˜¯åˆ†å¸ƒå¼è®­ç»ƒç›¸å…³ï¼Œä¼˜å…ˆé€‰ AI-Sys-Trainã€‚
    3. å¦‚æœæ˜¯ Agent æˆ– MCP ç›¸å…³ï¼Œä¼˜å…ˆé€‰ AI-App-Agentã€‚
    
    è¾“å‡ºåˆ†ç±»åç§°ï¼š
    """
    
    try:
        response = client.chat.completions.create(
            model=LLM_MODEL,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"LLM Error: {e}")
        return "Uncategorized"

def update_readme(data):
    """ç”Ÿæˆ Markdown"""
    # æŒ‰åˆ†ç±»åˆ†ç»„
    grouped = {cat.split(" ")[0]: [] for cat in CATEGORIES}
    grouped["Uncategorized"] = []
    
    for repo in data.values():
        cat_key = repo['category'].split(" ")[0] # æå– "AI-Sys-Train" è¿™ç§çŸ­å
        if cat_key not in grouped:
            cat_key = "Uncategorized"
        grouped[cat_key].append(repo)
    
    # ç”Ÿæˆå†…å®¹
    md = "# ğŸŒŸ My Awesome AI Stars\n\n> ğŸ¤– è‡ªåŠ¨ç”Ÿæˆäº GitHub Actions, Powered by LLM.\n\n"
    md += "## ç›®å½•\n"
    for cat in grouped.keys():
        if grouped[cat]:
            md += f"- [{cat}](#{cat.lower()})\n"
    
    md += "\n---\n"
    
    for cat, repos in grouped.items():
        if not repos: continue
        md += f"## {cat}\n\n"
        md += "| Project | Description | Stars | Category |\n"
        md += "|---|---|---|---|\n"
        # æŒ‰ Star æ•°å€’åºæ’åˆ—
        repos.sort(key=lambda x: x['stars'], reverse=True)
        for r in repos:
            desc = (r['description'] or "").replace("|", "\|") # è½¬ä¹‰è¡¨æ ¼ç¬¦
            md += f"| [{r['name']}]({r['url']}) | {desc} | {r['stars']} | {r['category']} |\n"
        md += "\n"
        
    with open("README.md", "w", encoding="utf-8") as f:
        f.write(md)

def main():
    # 1. è¯»å–ç¼“å­˜
    if os.path.exists(CACHE_FILE):
        with open(CACHE_FILE, 'r', encoding='utf-8') as f:
            cache = json.load(f)
    else:
        cache = {}

    # 2. è·å– GitHub Stars
    g = Github(GITHUB_TOKEN)
    user = g.get_user()
    print(f"Fetching stars for user: {user.login}...")
    
    starred_repos = user.get_starred()
    
    # 3. å¢é‡æ›´æ–°é€»è¾‘
    new_cache = {}
    is_updated = False
    
    # æ³¨æ„ï¼šè¿™é‡Œä¸ºäº†æ¼”ç¤ºåªå–å‰ 500 ä¸ªï¼Œå…¨é‡åŒæ­¥å¯å»æ‰åˆ‡ç‰‡ï¼Œä½†è¦æ³¨æ„ API é€Ÿç‡
    for repo in tqdm(starred_repos, total=starred_repos.totalCount):
        repo_id = str(repo.id)
        
        # å¦‚æœç¼“å­˜é‡Œæœ‰ï¼Œä¸”ä¸éœ€è¦å¼ºåˆ¶åˆ·æ–°ï¼Œç›´æ¥å¤ç”¨
        if repo_id in cache:
            # æ›´æ–° star æ•°ï¼ˆå› ä¸º star æ•°æ˜¯åŠ¨æ€çš„ï¼‰
            cache[repo_id]['stars'] = repo.stargazers_count
            new_cache[repo_id] = cache[repo_id]
        else:
            # æ–°å‘ç°çš„ä»“åº“ï¼Œè°ƒç”¨ LLM
            print(f"ğŸ¤– Classifying new repo: {repo.full_name}")
            category = get_llm_category(repo.name, repo.description or "")
            
            entry = {
                "name": repo.full_name,
                "url": repo.html_url,
                "description": repo.description,
                "stars": repo.stargazers_count,
                "category": category,
                "crawled_at": time.time()
            }
            new_cache[repo_id] = entry
            is_updated = True
            time.sleep(1) # é¿å… LLM Rate Limit
            
    # 4. ä¿å­˜ç¼“å­˜
    with open(CACHE_FILE, 'w', encoding='utf-8') as f:
        json.dump(new_cache, f, ensure_ascii=False, indent=2)
        
    # 5. ç”Ÿæˆ Readme
    update_readme(new_cache)
    print("Done!")

if __name__ == "__main__":
    main()
```

### 2.3 `.github/workflows/update.yml`
```yaml
name: Update Awesome Stars

on:
  workflow_dispatch: # æ‰‹åŠ¨è§¦å‘
  schedule:
    - cron: '0 0 * * *' # æ¯å¤© UTC 0ç‚¹è¿è¡Œ

permissions:
  contents: write

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        
    - name: Install dependencies
      run: pip install -r requirements.txt
      
    - name: Run classifier script
      env:
        GH_TOKEN: ${{ secrets.GH_TOKEN }} # éœ€è¦ä½ åœ¨ä»“åº“è®¾ç½® Secrets
        LLM_API_KEY: ${{ secrets.LLM_API_KEY }}
        LLM_BASE_URL: ${{ secrets.LLM_BASE_URL }} # å¯é€‰ï¼Œé»˜è®¤ DeepSeek
        LLM_MODEL: ${{ secrets.LLM_MODEL }}       # å¯é€‰
      run: python main.py
      
    - name: Commit and push if changed
      run: |
        git config --global user.email "action@github.com"
        git config --global user.name "GitHub Action"
        git add README.md stars_cache.json
        git commit -m "ğŸ¤– Auto-update stars classification" || exit 0
        git push
```
