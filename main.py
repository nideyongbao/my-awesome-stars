import os
import json
import time
import github
from github import Github
from openai import OpenAI
from tqdm import tqdm

# --- é…ç½®éƒ¨åˆ† ---
GITHUB_TOKEN = os.getenv("GH_TOKEN")
LLM_API_KEY = os.getenv("LLM_API_KEY")
LLM_BASE_URL = os.getenv("LLM_BASE_URL", "https://api.deepseek.com")
LLM_MODEL = os.getenv("LLM_MODEL", "deepseek-chat")

# --- é»˜è®¤åˆ†ç±»ä½“ç³» (æ ¹æ® docs/default_catrgories.md è®¾è®¡) ---
DEFAULT_CATEGORIES = [
    # AI System (æ ¸å¿ƒå…³æ³¨åŒº),
    "AI-Sys-Posttraining (å¤§æ¨¡å‹åè®­ç»ƒå­¦ä¹ æ¡†æ¶)",
    "AI-Sys-RL (å¼ºåŒ–å­¦ä¹ æ¡†æ¶, PPO, GRPO)",
    "AI-Sys-FineTuning (å¾®è°ƒä¸è½»é‡åŒ–è®­ç»ƒ, LoRA, PEFT, Unsloth)",
    "AI-Sys-Pretraining (é¢„è®­ç»ƒæ¡†æ¶, Megatron, deepspeed)",
    "AI-Sys-Inference (æ¨ç†å¼•æ“ä¸åç«¯, vLLM, TGI, TensorRT-LLM, llama.cpp)",
    "AI-Sys-Quantization (é‡åŒ–ä¸å‹ç¼©, GPTQ, AWQ, Bitsandbytes)",
    "AI-Sys-Kernel (é«˜æ€§èƒ½ç®—å­ä¸åº•å±‚ä¼˜åŒ–, FlashAttention, CUTLASS, OpenAI-Triton)",
    "AI-Sys-Compiler (ç¼–è¯‘å™¨ä¸å›¾ä¼˜åŒ–, TVM, MLIR, XLA, TorchCompile)",
    "AI-Sys-Framework (æ·±åº¦å­¦ä¹ æ¡†æ¶åº•åº§, PyTorch, TensorFlow, JAX, MXNet)",
    "AI-Sys-Cluster (é›†ç¾¤è°ƒåº¦ä¸ç¼–æ’, Kubernetes, Ray, Slurm, Skypilot)",
    "AI-Sys-MLOps (å®éªŒç®¡ç†ä¸æ¨¡å‹ç›‘æ§, MLflow, WandB, Prometheus)",
    "AI-Sys-Hardware (ç¡¬ä»¶æ¥å£ä¸é©±åŠ¨, CUDA, ROCm, Ascend, Metal)",
    # AI Data (æ•°æ®å·¥ç¨‹)
    "AI-Data-Dataset (å¼€æºæ•°æ®é›†, HuggingFace-Datasets, FineWeb, CommonCrawl)",
    "AI-Data-Pipeline (æ•°æ®å¤„ç†ç®¡çº¿ä¸ETL, Datatrove, Data-Juicer, Apache Beam)",
    "AI-Data-Synthetic (åˆæˆæ•°æ®ç”Ÿæˆ, Argilla, Distilabel, Self-Instruct)",
    "AI-Data-Crawl (ç½‘é¡µæŠ“å–ä¸çˆ¬è™«, Crawlee, Scrapy, Firecrawl)",
    "AI-Data-Labeling (æ•°æ®æ ‡æ³¨å·¥å…·, Label Studio, CVAT)",
    "AI-Data-Vector (å‘é‡æ•°æ®åº“ä¸ç´¢å¼•, Milvus, Chroma, Faiss, Pinecone)",
    # AI Algorithm & Models
    "AI-Algo-LLM (è¯­è¨€æ¨¡å‹æ¶æ„ä¸å¾®è°ƒ, Llama, Qwen, LoRA)",
    "AI-Algo-Vision (è®¡ç®—æœºè§†è§‰ä¸ç”Ÿæˆ, Stable Diffusion, YOLO)",
    "AI-Algo-Audio (è¯­éŸ³è¯†åˆ«ä¸åˆæˆ, Whisper, TTS)",
    "AI-Algo-Multi (å¤šæ¨¡æ€ä¸æ–°æ¶æ„, CLIP, Mamba, MoE)",
    "AI-Algo-Omni (å…¨æ¨¡æ€å¤§æ¨¡å‹, OpenAI, Anthropic)",
    "AI-Algo-Theory (çº¯ç†è®ºä»£ç , è®ºæ–‡å¤ç°, æ•°å­¦åº“)",
    # AI Engineering & Application
    "AI-App-Agent (æ™ºèƒ½ä½“, è§„åˆ’ä¸è®°å¿†, AutoGPT, MetaGPT)",
    "AI-App-RAG (æ£€ç´¢å¢å¼ºç”Ÿæˆä¸å‘é‡åº“, LangChain, LlamaIndex)",
    "AI-App-Framework (åº”ç”¨å¼€å‘æ¡†æ¶, Dify, Flowise)",
    "AI-App-MCP (Model Context Protocol)",
    # General Development
    "Dev-Web-FullStack (ç°ä»£Webå¼€å‘, Next.js, React, FastAPI)",
    "Dev-Infra-Cloud (äº‘åŸç”Ÿ, å®¹å™¨, K8s)",
    "Dev-DB-Storage (æ•°æ®åº“ä¸å­˜å‚¨, PostgreSQL, Redis)",
    "Dev-Lang-Core (ç¼–ç¨‹è¯­è¨€æ ¸å¿ƒèµ„æº, Rust, Python, C++)",
    "Dev-Sec (å®‰å…¨å·¥å…·ä¸é€†å‘å·¥ç¨‹)",
    # Tools & Misc
    "Tools-Efficiency (ç”Ÿäº§åŠ›ä¸ç»ˆç«¯å·¥å…·, Oh-My-Zsh, Raycast)",
    "Tools-Media (å›¾åƒè§†é¢‘å¤„ç†å·¥å…·, FFmpeg)",
    "CS-Education (æ•™ç¨‹, é¢è¯•, è·¯çº¿å›¾)",
    "Research-Paper (è®ºæ–‡ä»£ç å¤ç°, Arxiv)",
    "Uncategorized (æ— æ³•åˆ†ç±»)"
]

CACHE_FILE = "stars_cache.json"
CATEGORY_FILE = "categories.json"

# --- Prompt æ¨¡æ¿ (JSON è¾“å‡º + æ€ç»´é“¾) ---
PROMPT_TEMPLATE = """
ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„ AI Infra æ¶æ„å¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯å°† GitHub ä»“åº“ç²¾å‡†åˆ†ç±»ã€‚

### è¾“å…¥ä¿¡æ¯
- ä»“åº“å: {repo_name}
- æè¿°: {description}
- Topics: {topics}

### é¢„è®¾åˆ†ç±»ä½“ç³»
{categories_json}

### æ ¸å¿ƒå†³ç­–é€»è¾‘ (Priority Logic)
1. **AI System ç»†åˆ†åŸåˆ™**ï¼š
   - **Posttraining vs FineTuning**: å¦‚æœæ˜¯å…¨é‡è®­ç»ƒæ¡†æ¶é€‰ `AI-Sys-Posttraining`ï¼›å¦‚æœæ˜¯ LoRA/QLoRA ç­‰è½»é‡å¾®è°ƒåº“ï¼ˆå¦‚ PEFTï¼‰é€‰ `AI-Sys-FineTuning`ã€‚
   - **Compiler vs Kernel**: å¦‚æœæ˜¯ç«¯åˆ°ç«¯çš„ç¼–è¯‘å™¨ï¼ˆå¦‚ TVMï¼‰é€‰ `AI-Sys-Compiler`ï¼›å¦‚æœæ˜¯å…·ä½“çš„ç®—å­å®ç°ï¼ˆå¦‚ FlashAttentionï¼‰é€‰ `AI-Sys-Kernel`ã€‚
   - **Ops vs Cluster**: å¦‚æœæ˜¯ K8s/Ray/Slurm ç›¸å…³çš„è°ƒåº¦é€‰ `AI-Sys-Cluster`ï¼›å¦‚æœæ˜¯ WandB ç­‰æŒ‡æ ‡ç›‘æ§é€‰ `AI-Sys-MLOps`ã€‚

2. **AI Data ç»†åˆ†åŸåˆ™**ï¼š
   - **Vector vs RAG**: å¦‚æœæ˜¯å•çº¯çš„å‘é‡æ•°æ®åº“ï¼ˆå¦‚ Milvusï¼‰é€‰ `AI-Data-Vector`ï¼›å¦‚æœæ˜¯æ„å»º RAG åº”ç”¨çš„ç¼–æ’æ¡†æ¶ï¼ˆå¦‚ LangChainï¼‰é€‰ `AI-App-RAG`ã€‚
   - **Synthetic**: å‡¡æ˜¯æ¶‰åŠ "Synthetic Data" æˆ– "Distillation" çš„å·¥å…·ï¼Œä¼˜å…ˆé€‰ `AI-Data-Synthetic`ã€‚

3. **MCP ç‰¹åˆ«è§„åˆ™**:
   - å‡¡æ˜¯æåŠ "Model Context Protocol" æˆ– "MCP Server" çš„é¡¹ç›®ï¼Œå¿…é¡»å½’å…¥ `AI-App-MCP`ã€‚

4. **é€šç”¨è§„åˆ™**:
   - åªæœ‰å½“å®Œå…¨ä¸å±äº AI é¢†åŸŸæ—¶ï¼Œæ‰ä½¿ç”¨ `Dev-` æˆ– `Tools-` å¼€å¤´çš„åˆ†ç±»ã€‚

### è¾“å‡ºæ ¼å¼ (JSON)
{{
    "category": "Selected Category Name",
    "reasoning": "ç®€çŸ­ç†ç”±"
}}
"""


def load_categories():
    """åŠ è½½åˆ†ç±»ä½“ç³»ï¼Œå¦‚æœæœ‰åŠ¨æ€æ‰©å±•çš„åˆ†ç±»åˆ™åˆå¹¶"""
    if os.path.exists(CATEGORY_FILE):
        with open(CATEGORY_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return DEFAULT_CATEGORIES.copy()


def save_categories(categories):
    """ä¿å­˜åˆ†ç±»ä½“ç³»ï¼ˆåŒ…å«åŠ¨æ€æ‰©å±•çš„æ–°åˆ†ç±»ï¼‰"""
    with open(CATEGORY_FILE, 'w', encoding='utf-8') as f:
        json.dump(categories, f, ensure_ascii=False, indent=2)


def get_llm_classification(repo_name, description, topics, current_categories):
    """è°ƒç”¨ LLM è¿›è¡Œåˆ†ç±»ï¼Œè¿”å› JSON ç»“æœ"""
    client = OpenAI(api_key=LLM_API_KEY, base_url=LLM_BASE_URL)

    prompt = PROMPT_TEMPLATE.format(
        repo_name=repo_name,
        description=description,
        topics=", ".join(topics) if topics else "N/A",
        categories_json=json.dumps(current_categories, ensure_ascii=False, indent=2)
    )

    try:
        response = client.chat.completions.create(
            model=LLM_MODEL,
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"},  # å¼ºåˆ¶ JSON æ¨¡å¼
            temperature=0.1
        )
        result = json.loads(response.choices[0].message.content)
        return result
    except Exception as e:
        if "429" in str(e):
            print(f"âš ï¸ LLM Rate Limit hit for {repo_name}. Sleeping for 60s...")
            time.sleep(60)
        else:
            print(f"LLM Error: {e}")
        return {"category": "Uncategorized", "confidence": "low", "reasoning": "API Error"}


def update_readme(data, categories):
    """ç”Ÿæˆ README.md"""
    # åŠ¨æ€æ”¶é›†æ‰€æœ‰åˆ†ç±»
    all_categories = set()
    for repo in data.values():
        all_categories.add(repo['category'])

    # æ’åºï¼šä¼˜å…ˆ categories åˆ—è¡¨é¡ºåºï¼Œæ–°åˆ†ç±»æŒ‰å­—æ¯åºï¼ŒUncategorized æœ€å
    sorted_cats = []
    seen = set()

    for cat in categories:
        if cat in all_categories:
            sorted_cats.append(cat)
            seen.add(cat)

    remaining = [c for c in all_categories if c not in seen and c != "Uncategorized"]
    remaining.sort()
    sorted_cats.extend(remaining)

    if "Uncategorized" in all_categories:
        sorted_cats.append("Uncategorized")

    # åˆ†ç»„
    grouped = {cat: [] for cat in sorted_cats}
    for repo in data.values():
        cat = repo['category']
        if cat in grouped:
            grouped[cat].append(repo)
        else:
            if "Uncategorized" not in grouped:
                grouped["Uncategorized"] = []
            grouped["Uncategorized"].append(repo)

    # ç”Ÿæˆå†…å®¹
    md = "# ğŸŒŸ My Awesome AI Stars\n\n> ğŸ¤– è‡ªåŠ¨ç”Ÿæˆäº GitHub Actions, Powered by LLM.\n\n"
    md += "## ç›®å½•\n"
    for cat in sorted_cats:
        cat_key = cat.split(" ")[0]
        if " " not in cat:
            cat_key = cat
        count = len(grouped[cat])
        md += f"- [{cat} ({count})](#{cat_key.lower()})\n"

    md += "\n---\n"

    for cat in sorted_cats:
        repos = grouped[cat]
        if not repos:
            continue

        cat_key = cat.split(" ")[0]
        if " " not in cat:
            cat_key = cat

        md += f"## <span id='{cat_key.lower()}'>{cat}</span>\n\n"
        md += "| Project | Description | Stars | Language |\n"
        md += "|---|---|---|---|\n"
        repos.sort(key=lambda x: x['stars'], reverse=True)
        for r in repos:
            desc = (r.get('description') or "").replace("|", r"\|").replace("\n", " ")
            lang = r.get('language') or "N/A"
            md += f"| [{r['name']}]({r['url']}) | {desc[:100]} | {r['stars']} | {lang} |\n"
        md += "\n"

    with open("README.md", "w", encoding="utf-8") as f:
        f.write(md)


def main():
    # 1. åŠ è½½åˆ†ç±»ä½“ç³»
    categories = load_categories()

    # 2. è¯»å–ç¼“å­˜
    if os.path.exists(CACHE_FILE):
        with open(CACHE_FILE, 'r', encoding='utf-8') as f:
            cache = json.load(f)
    else:
        cache = {}

    # 3. è·å– GitHub Stars (ä½¿ç”¨æ–°ç‰ˆ Auth)
    auth = github.Auth.Token(GITHUB_TOKEN)
    g = Github(auth=auth)
    user = g.get_user()
    print(f"Fetching stars for user: {user.login}...")

    starred_repos = user.get_starred()

    # 4. å¢é‡æ›´æ–°é€»è¾‘
    new_cache = {}

    for repo in tqdm(starred_repos, total=starred_repos.totalCount):
        repo_id = str(repo.id)

        # å¦‚æœç¼“å­˜é‡Œæœ‰ï¼Œä¸”ä¸æ˜¯ Uncategorizedï¼Œç›´æ¥å¤ç”¨
        if repo_id in cache and cache[repo_id].get('category') != 'Uncategorized':
            cache[repo_id]['stars'] = repo.stargazers_count
            cache[repo_id]['language'] = repo.language
            new_cache[repo_id] = cache[repo_id]
        else:
            # æ–°ä»“åº“æˆ–éœ€è¦é‡æ–°åˆ†ç±»
            print(f"ğŸ¤– Classifying: {repo.full_name}")

            # è·å– Topics
            try:
                topics = repo.get_topics()
            except Exception:
                topics = []

            result = get_llm_classification(
                repo.name,
                repo.description or "",
                topics,
                categories
            )

            category_name = result.get("category", "Uncategorized")

            # --- åŠ¨æ€æ‰©å±•é€»è¾‘ ---
            if category_name not in categories and "(" in category_name:
                print(f"âœ¨ å‘ç°æ–°é¢†åŸŸï¼Œè‡ªåŠ¨æ‰©å±•åˆ†ç±»ä½“ç³»: {category_name}")
                categories.append(category_name)
                save_categories(categories)

            entry = {
                "name": repo.full_name,
                "url": repo.html_url,
                "description": repo.description,
                "stars": repo.stargazers_count,
                "category": category_name,
                "language": repo.language,
                "topics": topics,
                "confidence": result.get("confidence", "unknown"),
                "reasoning": result.get("reasoning", ""),
                "crawled_at": time.time()
            }
            new_cache[repo_id] = entry
            time.sleep(1)  # é¿å… LLM Rate Limit

    # 5. ä¿å­˜ç¼“å­˜
    with open(CACHE_FILE, 'w', encoding='utf-8') as f:
        json.dump(new_cache, f, ensure_ascii=False, indent=2)

    # 6. ä¿å­˜åˆ†ç±»ä½“ç³»
    save_categories(categories)

    # 7. ç”Ÿæˆ README
    update_readme(new_cache, categories)
    print("Done!")


if __name__ == "__main__":
    main()
