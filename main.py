import os
import json
import time
from github import Github
from openai import OpenAI
from tqdm import tqdm

# --- é…ç½®éƒ¨åˆ† ---
GITHUB_TOKEN = os.getenv("GH_TOKEN")
LLM_API_KEY = os.getenv("LLM_API_KEY")
LLM_BASE_URL = os.getenv("LLM_BASE_URL", "https://api.deepseek.com") # é»˜è®¤ä½¿ç”¨DeepSeekï¼Œå¯æ”¹
LLM_MODEL = os.getenv("LLM_MODEL", "deepseek-chat") 

# ä½ çš„åˆ†ç±»ä½“ç³»
CATEGORIES = [
    "AI-Sys-Train (è®­ç»ƒæ¡†æ¶, DeepSpeed, Megatron)",
    "AI-Sys-Inference (æ¨ç†ä¸éƒ¨ç½², vLLM, TGI)",
    "AI-Sys-Perf (æ€§èƒ½ä¼˜åŒ–, CUDA, Kernel)",
    "AI-Sys-Core (DLæ¡†æ¶åº•åº§, PyTorch, JAX)",
    "AI-Algo-Model (æ¨¡å‹æ¶æ„, Llama, Qwen)",
    "AI-App-Agent (Agent, CoT, Planner)",
    "AI-App-Utils (LangChain, RAG, PDFè§£æ)",
    "AI-Data (æ•°æ®é›†, æ•°æ®å¤„ç†)",
    "Dev-Web (å‰åç«¯å¼€å‘)",
    "Tools-CLI (å‘½ä»¤è¡Œå·¥å…·, æ•ˆç‡è„šæœ¬)",
    "Proj-RedLoop (RedLoopç›¸å…³é¡¹ç›®)",
    "Research-Other (å…¶ä»–ç ”ç©¶, é‡åŒ–ç­‰)",
    "Uncategorized (æ— æ³•åˆ†ç±»)"
]

CACHE_FILE = "stars_cache.json"

def get_llm_category(repo_name, description):
    """è°ƒç”¨ LLM è¿›è¡Œåˆ†ç±»"""
    client = OpenAI(api_key=LLM_API_KEY, base_url=LLM_BASE_URL)
    
    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯ä»“åº“åˆ†ç±»å™¨ã€‚è¯·æ ¹æ®ä»¥ä¸‹ GitHub ä»“åº“ä¿¡æ¯ï¼Œä»ç»™å®šçš„åˆ†ç±»åˆ—è¡¨ä¸­é€‰æ‹©æœ€åŒ¹é…çš„ä¸€ä¸ªã€‚
    
    ä»“åº“å: {repo_name}
    æè¿°: {description}
    
    å¯é€‰åˆ†ç±»åˆ—è¡¨ (ä»…ä¾›å‚è€ƒï¼Œå¦‚æœæ²¡æœ‰åˆé€‚çš„ï¼Œä½ å¯ä»¥æ–°å»ºä¸€ä¸ªç¬¦åˆæ ¼å¼çš„åˆ†ç±»):
    {json.dumps(CATEGORIES, ensure_ascii=False)}
    
    è§„åˆ™ï¼š
    1. åªèƒ½è¿”å›åˆ†ç±»åç§°å­—ç¬¦ä¸²ï¼Œä¸è¦è§£é‡Šã€‚
    2. å¦‚æœç°æœ‰åˆ†ç±»ä¸åˆé€‚ï¼Œè¯·ç”Ÿæˆä¸€ä¸ªæ–°çš„åˆ†ç±»ï¼Œæ ¼å¼å¿…é¡»ä¸º "Category-Name (Description)"ï¼Œä¾‹å¦‚ "AI-Audio (è¯­éŸ³åˆæˆä¸è¯†åˆ«)"ã€‚
    3. å¦‚æœæ˜¯åˆ†å¸ƒå¼è®­ç»ƒç›¸å…³ï¼Œä¼˜å…ˆé€‰ AI-Sys-Trainã€‚
    
    è¾“å‡ºåˆ†ç±»åç§°ï¼š
    """
    
    try:
        response = client.chat.completions.create(
            model=LLM_MODEL,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        # å¦‚æœæ˜¯ Rate Limit (429)ï¼Œæ‰“å°æ›´æ˜æ˜¾çš„è­¦å‘Š
        if "429" in str(e):
             print(f"âš ï¸ LLM Rate Limit hit for {repo_name}. Sleeping for 60s...")
             time.sleep(60)
        else:
             print(f"LLM Error: {e}")
        return "Uncategorized"

def update_readme(data):
    """ç”Ÿæˆ Markdown"""
    # åŠ¨æ€æ”¶é›†æ‰€æœ‰åˆ†ç±»
    all_categories = set()
    for repo in data.values():
        all_categories.add(repo['category'])
    
    # å°†æ ‡å‡†åˆ†ç±»å’Œæ–°å‘ç°çš„åˆ†ç±»åˆå¹¶å¹¶æ’åº
    # ä¼˜å…ˆå±•ç¤ºé…ç½®å¥½çš„ CATEGORIES é¡ºåºï¼Œæ–°åˆ†ç±»æŒ‰å­—æ¯åºæ’åœ¨åé¢
    sorted_cats = []
    seen = set()
    
    # 1. å…ˆåŠ é¢„å®šä¹‰çš„
    for cat in CATEGORIES:
        if cat in all_categories:
            sorted_cats.append(cat)
            seen.add(cat)
            
    # 2. å†åŠ æ–°ç”Ÿæˆçš„ (æ’é™¤ Uncategorized)
    remaining = [c for c in all_categories if c not in seen and c != "Uncategorized"]
    remaining.sort()
    sorted_cats.extend(remaining)
    
    # 3. æœ€ååŠ  Uncategorized
    if "Uncategorized" in all_categories:
        sorted_cats.append("Uncategorized")

    # åˆ†ç»„
    grouped = {cat: [] for cat in sorted_cats}
    for repo in data.values():
        cat = repo['category']
        if cat in grouped:
            grouped[cat].append(repo)
        else:
            # Fallback å¦‚æœæœ‰äº›å¥‡å¥‡æ€ªæ€ªçš„åˆ†ç±»æ²¡è¢«æ•è·
            if "Uncategorized" not in grouped:
                grouped["Uncategorized"] = []
            grouped["Uncategorized"].append(repo)
    
    # ç”Ÿæˆå†…å®¹
    md = "# ğŸŒŸ My Awesome AI Stars\n\n> ğŸ¤– è‡ªåŠ¨ç”Ÿæˆäº GitHub Actions, Powered by LLM.\n\n"
    md += "## ç›®å½•\n"
    for cat in sorted_cats:
        cat_key = cat.split(" ")[0] # æå– "AI-Sys-Train" ç”¨äºé”šç‚¹
        # å…¼å®¹ä¸€ä¸‹ï¼Œå¦‚æœç”Ÿæˆçš„åˆ†ç±»æ²¡æœ‰ç©ºæ ¼ï¼Œç›´æ¥ç”¨å…¨æ–‡
        if " " not in cat: 
             cat_key = cat
        
        count = len(grouped[cat])
        md += f"- [{cat} ({count})](#{cat_key.lower()})\n"
    
    md += "\n---\n"
    
    for cat in sorted_cats:
        repos = grouped[cat]
        if not repos: continue
        
        cat_key = cat.split(" ")[0]
        if " " not in cat: cat_key = cat
        
        md += f"## <span id='{cat_key.lower()}'>{cat}</span>\n\n"
        md += "| Project | Description | Stars | Language |\n"
        md += "|---|---|---|---|\n"
        # æŒ‰ Star æ•°å€’åºæ’åˆ—
        repos.sort(key=lambda x: x['stars'], reverse=True)
        for r in repos:
            desc = (r['description'] or "").replace("|", "\|") # è½¬ä¹‰è¡¨æ ¼ç¬¦
            lang = r.get('language') or "N/A"
            md += f"| [{r['name']}]({r['url']}) | {desc} | {r['stars']} | {lang} |\n"
        md += "\n"
        
    with open("README.md", "w", encoding="utf-8") as f:
        f.write(md)

def main():
    # 1. è¯»å–ç¼“å­˜
    if os.path.exists(CACHE_FILE):
        with open(CACHE_FILE, 'r', encoding='utf-8') as f:
            cache = json.load(f)
    else:
        cache = {}

    # 2. è·å– GitHub Stars
    # DeprecationWarning: Argument login_or_token is deprecated, please use auth=github.Auth.Token(...) instead
    from github import Auth
    auth = Auth.Token(GITHUB_TOKEN)
    g = Github(auth=auth)
    user = g.get_user()
    print(f"Fetching stars for user: {user.login}...")
    
    starred_repos = user.get_starred()
    
    # 3. å¢é‡æ›´æ–°é€»è¾‘
    new_cache = {}
    is_updated = False
    
    # æ³¨æ„ï¼šè¿™é‡Œä¸ºäº†æ¼”ç¤ºåªå–å‰ 500 ä¸ªï¼Œå…¨é‡åŒæ­¥å¯å»æ‰åˆ‡ç‰‡ï¼Œä½†è¦æ³¨æ„ API é€Ÿç‡
    for repo in tqdm(starred_repos, total=starred_repos.totalCount):
        repo_id = str(repo.id)
        
        # å¦‚æœç¼“å­˜é‡Œæœ‰ï¼Œä¸”ä¸éœ€è¦å¼ºåˆ¶åˆ·æ–°ï¼Œç›´æ¥å¤ç”¨
        # CHANGE: å¦‚æœä¹‹å‰æ˜¯ Uncategorizedï¼Œåˆ™é‡æ–°å°è¯•åˆ†ç±»
        if repo_id in cache and cache[repo_id].get('category') != 'Uncategorized':
            # æ›´æ–°åŠ¨æ€æ•°æ®: stars, language
            cache[repo_id]['stars'] = repo.stargazers_count
            cache[repo_id]['language'] = repo.language
            new_cache[repo_id] = cache[repo_id]
        else:
            # æ–°å‘ç°çš„ä»“åº“ï¼Œè°ƒç”¨ LLM
            print(f"ğŸ¤– Classifying new repo: {repo.full_name}")
            category = get_llm_category(repo.name, repo.description or "")
            
            entry = {
                "name": repo.full_name,
                "url": repo.html_url,
                "description": repo.description,
                "stars": repo.stargazers_count,
                "category": category,
                "language": repo.language,
                "crawled_at": time.time()
            }
            new_cache[repo_id] = entry
            is_updated = True
            time.sleep(1) # é¿å… LLM Rate Limit
            
    # 4. ä¿å­˜ç¼“å­˜
    with open(CACHE_FILE, 'w', encoding='utf-8') as f:
        json.dump(new_cache, f, ensure_ascii=False, indent=2)
        
    # 5. ç”Ÿæˆ Readme
    update_readme(new_cache)
    print("Done!")

if __name__ == "__main__":
    main()
