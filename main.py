import os
import json
import time
import github
from github import Github
from openai import OpenAI
from tqdm import tqdm

# --- é…ç½®éƒ¨åˆ† ---
GITHUB_TOKEN = os.getenv("GH_TOKEN")
LLM_API_KEY = os.getenv("LLM_API_KEY")
LLM_BASE_URL = os.getenv("LLM_BASE_URL", "https://api.deepseek.com")
LLM_MODEL = os.getenv("LLM_MODEL", "deepseek-chat")

# é…ç½®æ–‡ä»¶è·¯å¾„
CACHE_FILE = "stars_cache.json"
CATEGORY_FILE = "categories.json"

# --- Prompt æ¨¡æ¿ (JSON è¾“å‡º + æ€ç»´é“¾) ---
# åŸºäº note.md ä¸­çš„ "6+3" ä¸ªäººç ”ç©¶ä½“ç³»æ¡†æ¶
PROMPT_TEMPLATE = """
ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„ AI ç³»ç»Ÿå·¥ç¨‹å¸ˆå’Œå¼€æºç¤¾åŒºä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°† GitHub ä»“åº“ç²¾å‡†åˆ†ç±»åˆ°**ä¸ªäººç ”ç©¶ä½“ç³»æ¡†æ¶**ä¸­æœ€åŒ¹é…çš„ç±»åˆ«ã€‚

### è¾“å…¥ä¿¡æ¯
- ä»“åº“å: {repo_name}
- æè¿°: {description}
- Topics: {topics}

### é¢„è®¾åˆ†ç±»ä½“ç³» (6 å¤§æ ¸å¿ƒç ”ç©¶åŸŸ + 3 å¤§æ”¯æ’‘åŸºçŸ³)
{categories_json}

### æ ¸å¿ƒå†³ç­–é€»è¾‘ (Priority Logic)

#### ç¬¬ä¸€æ­¥ï¼šåˆ¤æ–­é¡¹ç›®ç±»å‹
1. **AI ç›¸å…³é¡¹ç›®**ï¼šæè¿°æˆ– Topics ä¸­åŒ…å« LLMã€MLã€AIã€æ¨¡å‹ã€è®­ç»ƒã€æ¨ç†ã€Transformerã€attentionã€embedding ç­‰å…³é”®è¯ â†’ è¿›å…¥ AI åˆ†ç±»å†³ç­–
2. **é€šç”¨å¼€å‘é¡¹ç›®**ï¼šä¸åŒ…å«ä¸Šè¿°å…³é”®è¯ â†’ ä½¿ç”¨ `Dev-`ã€`Tools-`ã€`CS-Education` ç­‰é€šç”¨åˆ†ç±»

#### ç¬¬äºŒæ­¥ï¼šAI é¡¹ç›®çš„ 6 å¤§ç ”ç©¶åŸŸåˆ†ç±»

**Domain 1: Compute & Acceleration (è®¡ç®—åŠ é€Ÿ)**
- **AI-Sys-Hardware**: CUDA/ROCm é©±åŠ¨ã€ç¡¬ä»¶æŠ½è±¡å±‚ã€Ascend/Metal åç«¯
- **AI-Sys-Kernel**: FlashAttentionã€CUTLASSã€Triton ç®—å­ã€æ‰‹å†™ CUDA kernel
- **AI-Sys-Compiler**: TVMã€MLIRã€XLAã€TorchCompileã€è®¡ç®—å›¾ä¼˜åŒ–
- **AI-Sys-Framework**: PyTorch/TensorFlow/JAX æ·±åº¦å­¦ä¹ æ¡†æ¶åº•åº§
- **AI-Sys-MLOps**: MLflow/WandB å®éªŒç®¡ç†ä¸ç›‘æ§

**Domain 2: Training Systems (è®­ç»ƒç³»ç»Ÿ)**
- **AI-Sys-Training**: åˆ†å¸ƒå¼è®­ç»ƒæ¡†æ¶å¦‚ DeepSpeed ZeROã€Megatronã€FSDPã€NanoGPT ç­‰ä»é›¶è®­ç»ƒå¤§æ¨¡å‹
- **AI-Sys-FineTuning**: LoRA/QLoRA/PEFT/Adapter è½»é‡å¾®è°ƒã€Unsloth ç­‰
- **AI-Sys-RLHF**: PPO/DPO/GRPO åè®­ç»ƒå¯¹é½ã€TRLã€OpenRLHFã€verl ç­‰ RL å¾®è°ƒæ¡†æ¶
- **AI-Sys-Cluster**: Ray/Slurm/Skypilot é›†ç¾¤è°ƒåº¦

**Domain 3: Data Systems (æ•°æ®ç³»ç»Ÿ)**
- **AI-Data-Pipeline**: Datatrove/Data-Juicer æ•°æ®æ¸…æ´—ç®¡çº¿
- **AI-Data-Synthetic**: Self-Instruct/Distilabel åˆæˆæ•°æ®ç”Ÿæˆ
- **AI-Data-Vector**: Milvus/Faiss/Chroma å‘é‡æ•°æ®åº“ï¼ˆæ³¨æ„ï¼šçº¯å‘é‡åº“é€‰æ­¤é¡¹ï¼ŒRAG æ¡†æ¶é€‰ AI-App-RAGï¼‰
- **AI-Data-Dataset**: å…¬å¼€æ•°æ®é›†ä»“åº“
- **AI-Data-Crawl**: çˆ¬è™«ã€æ•°æ®æŠ“å–å·¥å…·

**Domain 4: Inference Systems (æ¨ç†ç³»ç»Ÿ)**
- **AI-Sys-Inference**: vLLM/SGLang/TGI/llama.cpp/ollama æ¨ç†å¼•æ“
- **AI-Sys-Quantization**: GPTQ/AWQ/GGUF é‡åŒ–å‹ç¼©

**Domain 5: Model Behavior & Control (æ¨¡å‹è¡Œä¸ºä¸æ§åˆ¶)**
- **AI-Algo-LLM**: Llama/Qwen/DeepSeek/GLM ç­‰è¯­è¨€æ¨¡å‹æ¶æ„
- **AI-Algo-Multi**: CLIP/LLaVA/VLM å¤šæ¨¡æ€æ¨¡å‹ã€Mamba/MoE æ–°æ¶æ„
- **AI-Algo-Vision**: Stable Diffusion/YOLO/SAM è§†è§‰ç”Ÿæˆä¸æ£€æµ‹
- **AI-Algo-Audio**: Whisper/TTS è¯­éŸ³è¯†åˆ«ä¸åˆæˆ
- **AI-Algo-Robotics**: LeRobot/RT-X/VLA æœºå™¨äººä¸å…·èº«æ™ºèƒ½

**Domain 6: AI Applications (AI ç³»ç»ŸåŒ–åº”ç”¨)**
- **AI-App-Framework**: Dify/Flowise/LangGraph åº”ç”¨ç¼–æ’æ¡†æ¶
- **AI-App-RAG**: LangChain/LlamaIndex RAG æ£€ç´¢å¢å¼º
- **AI-App-Agent**: AutoGPT/MetaGPT/CrewAI æ™ºèƒ½ä½“æ¡†æ¶
- **AI-App-MCP**: ä»»ä½•æåŠ "Model Context Protocol" æˆ– "MCP Server" çš„é¡¹ç›® â†’ å¿…é¡»å½’å…¥æ­¤ç±»
- **AI-App-Coding**: Cursor/Copilot/Aider AI ç¼–ç¨‹åŠ©æ‰‹ã€Claude/Antigravity workflow

#### ç¬¬ä¸‰æ­¥ï¼šæ”¯æ’‘åŸºçŸ³åˆ†ç±»

**Pillar A: Theoretical Grounding (ç†è®ºåŸºçŸ³)**
- **AI-Algo-Theory**: æŸå¤±å‡½æ•°å®ç°ã€æ•°å­¦åº“ã€ç®—æ³•å¯è§†åŒ–
- **Research-Paper**: è®ºæ–‡å¤ç°ä»£ç ã€arXiv å®ç°

**Pillar B: Engineering & Delivery (å·¥ç¨‹åŸºçŸ³)**
- **Dev-Web-FullStack**: Next.js/React/Vue/FastAPI å…¨æ ˆå¼€å‘
- **Dev-Infra-Cloud**: Docker/K8s/Terraform äº‘åŸç”Ÿ
- **Dev-DB-Storage**: PostgreSQL/Redis/MongoDB æ•°æ®åº“
- **Dev-Lang-Core**: ç¼–ç¨‹è¯­è¨€æ ¸å¿ƒèµ„æº
- **Dev-Sec**: å®‰å…¨ã€æ¸—é€ã€é€†å‘

**Pillar C: AI-Native Workflow (AIå·¥ä½œæµåŸºçŸ³)**
- **Tools-Efficiency**: ç»ˆç«¯å·¥å…·ã€æ•ˆç‡å·¥å…·ã€Neovim/Obsidian
- **Tools-Media**: FFmpeg/yt-dlp éŸ³è§†é¢‘å¤„ç†

#### å…¶ä»–é€šç”¨åˆ†ç±»
- **CS-Education**: æ•™ç¨‹ã€é¢è¯•ã€å­¦ä¹ è·¯çº¿


#### ç‰¹æ®Šåˆ¤æ–­è§„åˆ™
1. **MCP æœ€é«˜ä¼˜å…ˆçº§**: å‡¡æ˜¯æåŠ "MCP"ã€"Model Context Protocol" æˆ– "mcp-server" â†’ ç›´æ¥å½’å…¥ `AI-App-MCP`
2. **Awesome-list é›†åˆ**: å¦‚æœæ˜¯èµ„æºæ±‡æ€»/awesome-list â†’ å½’å…¥ `CS-Education`
3. **Tutorial/æ•™ç¨‹**: ä¼˜å…ˆ `CS-Education`
4. **å…œåº•è§„åˆ™**: æ— æ³•ç¡®å®š â†’ `Uncategorized (æ— æ³•åˆ†ç±»)`

### è¾“å‡ºæ ¼å¼ (JSON)
{{
    "category": "é€‰æ‹©æœ€åŒ¹é…çš„å®Œæ•´åˆ†ç±»åï¼Œå¦‚ 'AI-Sys-Inference (æ¨ç†å¼•æ“ä¸åç«¯, vLLM, TGI, TensorRT-LLM, llama.cpp, SGLang)'",
    "reasoning": "ç®€çŸ­ç†ç”±ï¼ˆä¸€å¥è¯è¯´æ˜ä¸ºä½•é€‰æ‹©æ­¤åˆ†ç±»ï¼‰"
}}
"""


def load_categories():
    """ä» categories.json åŠ è½½åˆ†ç±»ä½“ç³»"""
    if not os.path.exists(CATEGORY_FILE):
        raise FileNotFoundError(f"åˆ†ç±»é…ç½®æ–‡ä»¶ {CATEGORY_FILE} ä¸å­˜åœ¨ï¼Œè¯·å…ˆåˆ›å»ºï¼")
    with open(CATEGORY_FILE, 'r', encoding='utf-8') as f:
        return json.load(f)


def save_categories(categories):
    """ä¿å­˜åˆ†ç±»ä½“ç³»ï¼ˆåŒ…å«åŠ¨æ€æ‰©å±•çš„æ–°åˆ†ç±»ï¼‰"""
    with open(CATEGORY_FILE, 'w', encoding='utf-8') as f:
        json.dump(categories, f, ensure_ascii=False, indent=2)


def get_llm_classification(repo_name, description, topics, current_categories):
    """è°ƒç”¨ LLM è¿›è¡Œåˆ†ç±»ï¼Œè¿”å› JSON ç»“æœ"""
    client = OpenAI(api_key=LLM_API_KEY, base_url=LLM_BASE_URL)
    default_result = {"category": "Uncategorized", "confidence": "low", "reasoning": "API Error or Invalid Response"}

    prompt = PROMPT_TEMPLATE.format(
        repo_name=repo_name,
        description=description,
        topics=", ".join(topics) if topics else "N/A",
        categories_json=json.dumps(current_categories, ensure_ascii=False, indent=2)
    )

    try:
        response = client.chat.completions.create(
            model=LLM_MODEL,
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"},  # å¼ºåˆ¶ JSON æ¨¡å¼
            temperature=0.1
        )
        
        # è°ƒè¯•æ—¥å¿—ï¼šæ‰“å°å®Œæ•´å“åº”ç»“æ„
        print(f"ğŸ“¡ API Response for {repo_name}:")
        print(f"   - Model: {LLM_MODEL}")
        print(f"   - Choices count: {len(response.choices) if response.choices else 0}")
        if response.choices:
            print(f"   - Finish reason: {response.choices[0].finish_reason}")
        
        # æ ¡éªŒ response ç»“æ„
        if not response.choices:
            print(f"LLM Error: Empty choices for {repo_name}")
            return default_result
        
        content = response.choices[0].message.content
        print(f"ğŸ“ LLM Raw Response for {repo_name}: {content[:200] if content else 'None'}...")  # è°ƒè¯•æ—¥å¿—
        
        if not content:
            print(f"LLM Error: Empty content for {repo_name}")
            return default_result
        
        result = json.loads(content)
        print(f"âœ… Parsed Result: category={result.get('category', 'N/A')}, reasoning={result.get('reasoning', 'N/A')[:50]}...")
        
        # æ ¡éªŒ result æ˜¯å¦ä¸ºæœ‰æ•ˆ dict ä¸”åŒ…å« category å­—æ®µ
        if not isinstance(result, dict):
            print(f"LLM Error: Result is not a dict for {repo_name}, got: {type(result)}")
            return default_result
        
        if "category" not in result:
            print(f"LLM Warning: Missing 'category' key for {repo_name}, using Uncategorized")
            result["category"] = "Uncategorized"
        
        return result
    except Exception as e:
        if "429" in str(e):
            print(f"âš ï¸ LLM Rate Limit hit for {repo_name}. Sleeping for 60s...")
            time.sleep(60)
            return get_llm_classification(repo_name, description, topics, current_categories)  # é‡è¯•
        else:
            print(f"LLM Error: {e}")
        return default_result


def update_readme(data, categories):
    """ç”Ÿæˆ README.md"""
    # åŠ¨æ€æ”¶é›†æ‰€æœ‰åˆ†ç±»
    all_categories = set()
    for repo in data.values():
        all_categories.add(repo['category'])

    # æ’åºï¼šä¼˜å…ˆ categories åˆ—è¡¨é¡ºåºï¼Œæ–°åˆ†ç±»æŒ‰å­—æ¯åºï¼ŒUncategorized æœ€å
    sorted_cats = []
    seen = set()

    for cat in categories:
        if cat in all_categories:
            sorted_cats.append(cat)
            seen.add(cat)

    remaining = [c for c in all_categories if c not in seen and c != "Uncategorized"]
    remaining.sort()
    sorted_cats.extend(remaining)

    if "Uncategorized" in all_categories:
        sorted_cats.append("Uncategorized")

    # åˆ†ç»„
    grouped = {cat: [] for cat in sorted_cats}
    for repo in data.values():
        cat = repo['category']
        if cat in grouped:
            grouped[cat].append(repo)
        else:
            if "Uncategorized" not in grouped:
                grouped["Uncategorized"] = []
            grouped["Uncategorized"].append(repo)

    # ç”Ÿæˆå†…å®¹
    md = "# ğŸŒŸ My Awesome AI Stars\n\n> ğŸ¤– è‡ªåŠ¨ç”Ÿæˆäº GitHub Actions, Powered by LLM.\n\n"
    md += "## ç›®å½•\n"
    for cat in sorted_cats:
        cat_key = cat.split(" ")[0]
        if " " not in cat:
            cat_key = cat
        count = len(grouped[cat])
        md += f"- [{cat} ({count})](#{cat_key.lower()})\n"

    md += "\n---\n"

    for cat in sorted_cats:
        repos = grouped[cat]
        if not repos:
            continue

        cat_key = cat.split(" ")[0]
        if " " not in cat:
            cat_key = cat

        md += f"## <span id='{cat_key.lower()}'>{cat}</span>\n\n"
        md += "| Project | Description | Stars | Language |\n"
        md += "|---|---|---|---|\n"
        repos.sort(key=lambda x: x['stars'], reverse=True)
        for r in repos:
            desc = (r.get('description') or "").replace("|", r"\|").replace("\n", " ")
            lang = r.get('language') or "N/A"
            md += f"| [{r['name']}]({r['url']}) | {desc[:100]} | {r['stars']} | {lang} |\n"
        md += "\n"

    with open("README.md", "w", encoding="utf-8") as f:
        f.write(md)


def main():
    # 1. åŠ è½½åˆ†ç±»ä½“ç³»
    categories = load_categories()

    # 2. è¯»å–ç¼“å­˜
    if os.path.exists(CACHE_FILE):
        with open(CACHE_FILE, 'r', encoding='utf-8') as f:
            cache = json.load(f)
    else:
        cache = {}

    # 3. è·å– GitHub Stars (ä½¿ç”¨æ–°ç‰ˆ Auth)
    auth = github.Auth.Token(GITHUB_TOKEN)
    g = Github(auth=auth)
    user = g.get_user()
    print(f"Fetching stars for user: {user.login}...")

    starred_repos = user.get_starred()

    # 4. å¢é‡æ›´æ–°é€»è¾‘
    new_cache = {}

    for repo in tqdm(starred_repos, total=starred_repos.totalCount):
        repo_id = str(repo.id)

        # å¦‚æœç¼“å­˜é‡Œæœ‰ï¼Œä¸”ä¸æ˜¯ Uncategorizedï¼Œç›´æ¥å¤ç”¨
        if repo_id in cache and cache[repo_id].get('category') != 'Uncategorized':
            cache[repo_id]['stars'] = repo.stargazers_count
            cache[repo_id]['language'] = repo.language
            new_cache[repo_id] = cache[repo_id]
        else:
            # æ–°ä»“åº“æˆ–éœ€è¦é‡æ–°åˆ†ç±»
            print(f"ğŸ¤– Classifying: {repo.full_name}")

            # è·å– Topics
            try:
                topics = repo.get_topics()
            except Exception:
                topics = []

            result = get_llm_classification(
                repo.name,
                repo.description or "",
                topics,
                categories
            )

            category_name = result.get("category", "Uncategorized")

            # --- åŠ¨æ€æ‰©å±•é€»è¾‘ ---
            if category_name not in categories and "(" in category_name:
                print(f"âœ¨ å‘ç°æ–°é¢†åŸŸï¼Œè‡ªåŠ¨æ‰©å±•åˆ†ç±»ä½“ç³»: {category_name}")
                categories.append(category_name)
                save_categories(categories)

            entry = {
                "name": repo.full_name,
                "url": repo.html_url,
                "description": repo.description,
                "stars": repo.stargazers_count,
                "category": category_name,
                "language": repo.language,
                "topics": topics,
                "confidence": result.get("confidence", "unknown"),
                "reasoning": result.get("reasoning", ""),
                "crawled_at": time.time()
            }
            new_cache[repo_id] = entry
            time.sleep(1)  # é¿å… LLM Rate Limit

    # 5. ä¿å­˜ç¼“å­˜
    with open(CACHE_FILE, 'w', encoding='utf-8') as f:
        json.dump(new_cache, f, ensure_ascii=False, indent=2)

    # 6. ä¿å­˜åˆ†ç±»ä½“ç³»
    save_categories(categories)

    # 7. ç”Ÿæˆ README
    update_readme(new_cache, categories)
    print("Done!")


if __name__ == "__main__":
    main()
