import os
import json
import time
from github import Github
from openai import OpenAI
from tqdm import tqdm

# --- é…ç½®éƒ¨åˆ† ---
GITHUB_TOKEN = os.getenv("GH_TOKEN")
LLM_API_KEY = os.getenv("LLM_API_KEY")
LLM_BASE_URL = os.getenv("LLM_BASE_URL", "https://api.deepseek.com") # é»˜è®¤ä½¿ç”¨DeepSeekï¼Œå¯æ”¹
LLM_MODEL = os.getenv("LLM_MODEL", "deepseek-chat") 

# ä½ çš„åˆ†ç±»ä½“ç³»
CATEGORIES = [
    "AI-Sys-Train (è®­ç»ƒæ¡†æ¶, DeepSpeed, Megatron)",
    "AI-Sys-Inference (æ¨ç†ä¸éƒ¨ç½², vLLM, TGI)",
    "AI-Sys-Perf (æ€§èƒ½ä¼˜åŒ–, CUDA, Kernel)",
    "AI-Sys-Core (DLæ¡†æ¶åº•åº§, PyTorch, JAX)",
    "AI-Algo-Model (æ¨¡å‹æ¶æ„, Llama, Qwen)",
    "AI-App-Agent (Agent, CoT, Planner)",
    "AI-App-Utils (LangChain, RAG, PDFè§£æ)",
    "AI-Data (æ•°æ®é›†, æ•°æ®å¤„ç†)",
    "Dev-Web (å‰åç«¯å¼€å‘)",
    "Tools-CLI (å‘½ä»¤è¡Œå·¥å…·, æ•ˆç‡è„šæœ¬)",
    "Proj-RedLoop (RedLoopç›¸å…³é¡¹ç›®)",
    "Research-Other (å…¶ä»–ç ”ç©¶, é‡åŒ–ç­‰)",
    "Uncategorized (æ— æ³•åˆ†ç±»)"
]

CACHE_FILE = "stars_cache.json"

def get_llm_category(repo_name, description):
    """è°ƒç”¨ LLM è¿›è¡Œåˆ†ç±»"""
    client = OpenAI(api_key=LLM_API_KEY, base_url=LLM_BASE_URL)
    
    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯ä»“åº“åˆ†ç±»å™¨ã€‚è¯·æ ¹æ®ä»¥ä¸‹ GitHub ä»“åº“ä¿¡æ¯ï¼Œä»ç»™å®šçš„åˆ†ç±»åˆ—è¡¨ä¸­é€‰æ‹©æœ€åŒ¹é…çš„ä¸€ä¸ªã€‚
    
    ä»“åº“å: {repo_name}
    æè¿°: {description}
    
    å¯é€‰åˆ†ç±»åˆ—è¡¨:
    {json.dumps(CATEGORIES, ensure_ascii=False)}
    
    è§„åˆ™ï¼š
    1. åªèƒ½è¿”å›åˆ—è¡¨ä¸­çš„æŸä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œä¸è¦è§£é‡Šã€‚
    2. å¦‚æœæ˜¯åˆ†å¸ƒå¼è®­ç»ƒç›¸å…³ï¼Œä¼˜å…ˆé€‰ AI-Sys-Trainã€‚
    3. å¦‚æœæ˜¯ Agent æˆ– MCP ç›¸å…³ï¼Œä¼˜å…ˆé€‰ AI-App-Agentã€‚
    
    è¾“å‡ºåˆ†ç±»åç§°ï¼š
    """
    
    try:
        response = client.chat.completions.create(
            model=LLM_MODEL,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        # å¦‚æœæ˜¯ Rate Limit (429)ï¼Œæ‰“å°æ›´æ˜æ˜¾çš„è­¦å‘Š
        if "429" in str(e):
             print(f"âš ï¸ LLM Rate Limit hit for {repo_name}. Sleeping for 60s...")
             time.sleep(60)
        else:
             print(f"LLM Error: {e}")
        return "Uncategorized"

def update_readme(data):
    """ç”Ÿæˆ Markdown"""
    # æŒ‰åˆ†ç±»åˆ†ç»„
    grouped = {cat.split(" ")[0]: [] for cat in CATEGORIES}
    grouped["Uncategorized"] = []
    
    for repo in data.values():
        cat_key = repo['category'].split(" ")[0] # æå– "AI-Sys-Train" è¿™ç§çŸ­å
        if cat_key not in grouped:
            cat_key = "Uncategorized"
        grouped[cat_key].append(repo)
    
    # ç”Ÿæˆå†…å®¹
    md = "# ğŸŒŸ My Awesome AI Stars\n\n> ğŸ¤– è‡ªåŠ¨ç”Ÿæˆäº GitHub Actions, Powered by LLM.\n\n"
    md += "## ç›®å½•\n"
    for cat in grouped.keys():
        if grouped[cat]:
            md += f"- [{cat}](#{cat.lower()})\n"
    
    md += "\n---\n"
    
    for cat, repos in grouped.items():
        if not repos: continue
        md += f"## {cat}\n\n"
        md += "| Project | Description | Stars | Category |\n"
        md += "|---|---|---|---|\n"
        # æŒ‰ Star æ•°å€’åºæ’åˆ—
        repos.sort(key=lambda x: x['stars'], reverse=True)
        for r in repos:
            desc = (r['description'] or "").replace("|", "\|") # è½¬ä¹‰è¡¨æ ¼ç¬¦
            md += f"| [{r['name']}]({r['url']}) | {desc} | {r['stars']} | {r['category']} |\n"
        md += "\n"
        
    with open("README.md", "w", encoding="utf-8") as f:
        f.write(md)

def main():
    # 1. è¯»å–ç¼“å­˜
    if os.path.exists(CACHE_FILE):
        with open(CACHE_FILE, 'r', encoding='utf-8') as f:
            cache = json.load(f)
    else:
        cache = {}

    # 2. è·å– GitHub Stars
    g = Github(GITHUB_TOKEN)
    user = g.get_user()
    print(f"Fetching stars for user: {user.login}...")
    
    starred_repos = user.get_starred()
    
    # 3. å¢é‡æ›´æ–°é€»è¾‘
    new_cache = {}
    is_updated = False
    
    # æ³¨æ„ï¼šè¿™é‡Œä¸ºäº†æ¼”ç¤ºåªå–å‰ 500 ä¸ªï¼Œå…¨é‡åŒæ­¥å¯å»æ‰åˆ‡ç‰‡ï¼Œä½†è¦æ³¨æ„ API é€Ÿç‡
    for repo in tqdm(starred_repos, total=starred_repos.totalCount):
        repo_id = str(repo.id)
        
        # å¦‚æœç¼“å­˜é‡Œæœ‰ï¼Œä¸”ä¸éœ€è¦å¼ºåˆ¶åˆ·æ–°ï¼Œç›´æ¥å¤ç”¨
        # CHANGE: å¦‚æœä¹‹å‰æ˜¯ Uncategorizedï¼Œåˆ™é‡æ–°å°è¯•åˆ†ç±»
        if repo_id in cache and cache[repo_id].get('category') != 'Uncategorized':
            # æ›´æ–° star æ•°
            cache[repo_id]['stars'] = repo.stargazers_count
            new_cache[repo_id] = cache[repo_id]
        else:
            # æ–°å‘ç°çš„ä»“åº“ï¼Œè°ƒç”¨ LLM
            print(f"ğŸ¤– Classifying new repo: {repo.full_name}")
            category = get_llm_category(repo.name, repo.description or "")
            
            entry = {
                "name": repo.full_name,
                "url": repo.html_url,
                "description": repo.description,
                "stars": repo.stargazers_count,
                "category": category,
                "crawled_at": time.time()
            }
            new_cache[repo_id] = entry
            is_updated = True
            time.sleep(1) # é¿å… LLM Rate Limit
            
    # 4. ä¿å­˜ç¼“å­˜
    with open(CACHE_FILE, 'w', encoding='utf-8') as f:
        json.dump(new_cache, f, ensure_ascii=False, indent=2)
        
    # 5. ç”Ÿæˆ Readme
    update_readme(new_cache)
    print("Done!")

if __name__ == "__main__":
    main()
