import os
import json
import time
import github
from github import Github
from openai import OpenAI
from tqdm import tqdm

# --- é…ç½®éƒ¨åˆ† ---
GITHUB_TOKEN = os.getenv("GH_TOKEN")
LLM_API_KEY = os.getenv("LLM_API_KEY")
LLM_BASE_URL = os.getenv("LLM_BASE_URL", "https://api.deepseek.com")
LLM_MODEL = os.getenv("LLM_MODEL", "deepseek-chat")

# --- é»˜è®¤åˆ†ç±»ä½“ç³» (æ ¹æ® docs/default_catrgories.md è®¾è®¡) ---
DEFAULT_CATEGORIES = [
    # AI System (æ ¸å¿ƒå…³æ³¨åŒº)
    "AI-Sys-Train (åˆ†å¸ƒå¼è®­ç»ƒæ¡†æ¶, DeepSpeed, Megatron-LM)",
    "AI-Sys-Inference (æ¨ç†å¼•æ“ä¸åç«¯, vLLM, TGI, TensorRT-LLM)",
    "AI-Sys-Compiler (ç¼–è¯‘å™¨ä¸å›¾ä¼˜åŒ–, TVM, MLIR, Triton)",
    "AI-Sys-Device (å¼‚æ„è®¡ç®—ä¸ç¡¬ä»¶æ¥å£, CUDA, ROCm)",
    "AI-Sys-Ops (MLOps, å®éªŒç®¡ç†, æ¨¡å‹ç›‘æ§)",
    # AI Algorithm & Models
    "AI-Algo-LLM (è¯­è¨€æ¨¡å‹æ¶æ„ä¸å¾®è°ƒ, Llama, Qwen, LoRA)",
    "AI-Algo-Vision (è®¡ç®—æœºè§†è§‰ä¸ç”Ÿæˆ, Stable Diffusion, YOLO)",
    "AI-Algo-Audio (è¯­éŸ³è¯†åˆ«ä¸åˆæˆ, Whisper, TTS)",
    "AI-Algo-Multi (å¤šæ¨¡æ€ä¸æ–°æ¶æ„, CLIP, Mamba, MoE)",
    "AI-Algo-Theory (çº¯ç†è®ºä»£ç , è®ºæ–‡å¤ç°, æ•°å­¦åº“)",
    # AI Engineering & Application
    "AI-App-Agent (æ™ºèƒ½ä½“, è§„åˆ’ä¸è®°å¿†, AutoGPT, MetaGPT)",
    "AI-App-RAG (æ£€ç´¢å¢å¼ºç”Ÿæˆä¸å‘é‡åº“, LangChain, LlamaIndex)",
    "AI-App-Framework (åº”ç”¨å¼€å‘æ¡†æ¶, Dify, Flowise)",
    "AI-Data-Eng (æ•°æ®å¤„ç†, ETL, æ ‡æ³¨å·¥å…·)",
    # General Development
    "Dev-Web-FullStack (ç°ä»£Webå¼€å‘, Next.js, React, FastAPI)",
    "Dev-Infra-Cloud (äº‘åŸç”Ÿ, å®¹å™¨, K8s)",
    "Dev-DB-Storage (æ•°æ®åº“ä¸å­˜å‚¨, PostgreSQL, Redis)",
    "Dev-Lang-Core (ç¼–ç¨‹è¯­è¨€æ ¸å¿ƒèµ„æº, Rust, Python, C++)",
    "Dev-Sec (å®‰å…¨å·¥å…·ä¸é€†å‘å·¥ç¨‹)",
    # Tools & Misc
    "Tools-Efficiency (ç”Ÿäº§åŠ›ä¸ç»ˆç«¯å·¥å…·, Oh-My-Zsh, Raycast)",
    "Tools-Media (å›¾åƒè§†é¢‘å¤„ç†å·¥å…·, FFmpeg)",
    "Proj-RedLoop (RedLoopç›¸å…³é¡¹ç›®)",
    "CS-Education (æ•™ç¨‹, é¢è¯•, è·¯çº¿å›¾)",
    "Uncategorized (æ— æ³•åˆ†ç±»)"
]

CACHE_FILE = "stars_cache.json"
CATEGORY_FILE = "categories.json"

# --- Prompt æ¨¡æ¿ (JSON è¾“å‡º + æ€ç»´é“¾) ---
PROMPT_TEMPLATE = """
ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„ GitHub ä»“åº“åˆ†ç±»ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†ç»™å®šçš„ä»“åº“å½’ç±»åˆ°æœ€åˆé€‚çš„ç±»åˆ«ä¸­ã€‚

### è¾“å…¥ä¿¡æ¯
- ä»“åº“å: {repo_name}
- æè¿°: {description}
- ä¸»è¦è¯­è¨€/Topics: {topics}

### é¢„è®¾åˆ†ç±»ä½“ç³» (Name: Description)
{categories_json}

### å†³ç­–é€»è¾‘
1. **ä¼˜å…ˆåŒ¹é…**ï¼šé¦–å…ˆå°è¯•ä»[é¢„è®¾åˆ†ç±»ä½“ç³»]ä¸­å¯»æ‰¾æœ€åŒ¹é…çš„ç±»åˆ«ã€‚
   - å¦‚æœæ˜¯åº•å±‚ç®—å­ã€CUDAä¼˜åŒ–ï¼Œå¿…é¡»é€‰ `AI-Sys-` å¼€å¤´çš„ç±»åˆ«ã€‚
   - å¦‚æœæ˜¯ Agent æˆ– RAG ç›¸å…³ï¼Œä¼˜å…ˆé€‰ `AI-App-` å¼€å¤´çš„ç±»åˆ«ã€‚
2. **æ–°å»ºåˆ†ç±»**ï¼šåªæœ‰å½“[é¢„è®¾åˆ†ç±»ä½“ç³»]ä¸­**å®Œå…¨æ²¡æœ‰**åˆé€‚çš„ç±»åˆ«æ—¶ï¼ˆä¾‹å¦‚é‡åˆ°äº†åŒºå—é“¾ã€é‡å­è®¡ç®—ç­‰æ–°é¢†åŸŸï¼‰ï¼Œæ‰å…è®¸æ–°å»ºåˆ†ç±»ã€‚
   - æ–°åˆ†ç±»æ ¼å¼å¿…é¡»ä¸ºï¼š`New-Category-Name (ç®€çŸ­ä¸­æ–‡æè¿°)`ã€‚
   - ä¾‹å¦‚ï¼š`Tech-Blockchain (åŒºå—é“¾ä¸Web3)`ã€‚
   - ä¸¥ç¦åˆ›å»ºä¸ç°æœ‰ä½“ç³»é‡å çš„åˆ†ç±»ï¼ˆä¾‹å¦‚ä¸è¦åˆ›å»º `Web-Frontend`ï¼Œå› ä¸ºå·²æœ‰ `Dev-Web-FullStack`ï¼‰ã€‚

### è¾“å‡ºæ ¼å¼ (å¿…é¡»æ˜¯çº¯ JSON)
è¯·ä»…è¾“å‡ºä¸€ä¸ª JSON å¯¹è±¡ï¼Œä¸è¦åŒ…å« Markdown æ ‡è®°æˆ–å…¶ä»–æ–‡æœ¬ï¼š
{{
    "category": "åˆ†ç±»åç§° (æè¿°)",
    "confidence": "high/medium/low",
    "reasoning": "ç®€çŸ­çš„åˆ†ç±»ç†ç”±ï¼ˆ10ä¸ªå­—ä»¥å†…ï¼‰"
}}
"""


def load_categories():
    """åŠ è½½åˆ†ç±»ä½“ç³»ï¼Œå¦‚æœæœ‰åŠ¨æ€æ‰©å±•çš„åˆ†ç±»åˆ™åˆå¹¶"""
    if os.path.exists(CATEGORY_FILE):
        with open(CATEGORY_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return DEFAULT_CATEGORIES.copy()


def save_categories(categories):
    """ä¿å­˜åˆ†ç±»ä½“ç³»ï¼ˆåŒ…å«åŠ¨æ€æ‰©å±•çš„æ–°åˆ†ç±»ï¼‰"""
    with open(CATEGORY_FILE, 'w', encoding='utf-8') as f:
        json.dump(categories, f, ensure_ascii=False, indent=2)


def get_llm_classification(repo_name, description, topics, current_categories):
    """è°ƒç”¨ LLM è¿›è¡Œåˆ†ç±»ï¼Œè¿”å› JSON ç»“æœ"""
    client = OpenAI(api_key=LLM_API_KEY, base_url=LLM_BASE_URL)

    prompt = PROMPT_TEMPLATE.format(
        repo_name=repo_name,
        description=description,
        topics=", ".join(topics) if topics else "N/A",
        categories_json=json.dumps(current_categories, ensure_ascii=False, indent=2)
    )

    try:
        response = client.chat.completions.create(
            model=LLM_MODEL,
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"},  # å¼ºåˆ¶ JSON æ¨¡å¼
            temperature=0.1
        )
        result = json.loads(response.choices[0].message.content)
        return result
    except Exception as e:
        if "429" in str(e):
            print(f"âš ï¸ LLM Rate Limit hit for {repo_name}. Sleeping for 60s...")
            time.sleep(60)
        else:
            print(f"LLM Error: {e}")
        return {"category": "Uncategorized", "confidence": "low", "reasoning": "API Error"}


def update_readme(data, categories):
    """ç”Ÿæˆ README.md"""
    # åŠ¨æ€æ”¶é›†æ‰€æœ‰åˆ†ç±»
    all_categories = set()
    for repo in data.values():
        all_categories.add(repo['category'])

    # æ’åºï¼šä¼˜å…ˆ categories åˆ—è¡¨é¡ºåºï¼Œæ–°åˆ†ç±»æŒ‰å­—æ¯åºï¼ŒUncategorized æœ€å
    sorted_cats = []
    seen = set()

    for cat in categories:
        if cat in all_categories:
            sorted_cats.append(cat)
            seen.add(cat)

    remaining = [c for c in all_categories if c not in seen and c != "Uncategorized"]
    remaining.sort()
    sorted_cats.extend(remaining)

    if "Uncategorized" in all_categories:
        sorted_cats.append("Uncategorized")

    # åˆ†ç»„
    grouped = {cat: [] for cat in sorted_cats}
    for repo in data.values():
        cat = repo['category']
        if cat in grouped:
            grouped[cat].append(repo)
        else:
            if "Uncategorized" not in grouped:
                grouped["Uncategorized"] = []
            grouped["Uncategorized"].append(repo)

    # ç”Ÿæˆå†…å®¹
    md = "# ğŸŒŸ My Awesome AI Stars\n\n> ğŸ¤– è‡ªåŠ¨ç”Ÿæˆäº GitHub Actions, Powered by LLM.\n\n"
    md += "## ç›®å½•\n"
    for cat in sorted_cats:
        cat_key = cat.split(" ")[0]
        if " " not in cat:
            cat_key = cat
        count = len(grouped[cat])
        md += f"- [{cat} ({count})](#{cat_key.lower()})\n"

    md += "\n---\n"

    for cat in sorted_cats:
        repos = grouped[cat]
        if not repos:
            continue

        cat_key = cat.split(" ")[0]
        if " " not in cat:
            cat_key = cat

        md += f"## <span id='{cat_key.lower()}'>{cat}</span>\n\n"
        md += "| Project | Description | Stars | Language |\n"
        md += "|---|---|---|---|\n"
        repos.sort(key=lambda x: x['stars'], reverse=True)
        for r in repos:
            desc = (r.get('description') or "").replace("|", r"\|").replace("\n", " ")
            lang = r.get('language') or "N/A"
            md += f"| [{r['name']}]({r['url']}) | {desc[:100]} | {r['stars']} | {lang} |\n"
        md += "\n"

    with open("README.md", "w", encoding="utf-8") as f:
        f.write(md)


def main():
    # 1. åŠ è½½åˆ†ç±»ä½“ç³»
    categories = load_categories()

    # 2. è¯»å–ç¼“å­˜
    if os.path.exists(CACHE_FILE):
        with open(CACHE_FILE, 'r', encoding='utf-8') as f:
            cache = json.load(f)
    else:
        cache = {}

    # 3. è·å– GitHub Stars (ä½¿ç”¨æ–°ç‰ˆ Auth)
    auth = github.Auth.Token(GITHUB_TOKEN)
    g = Github(auth=auth)
    user = g.get_user()
    print(f"Fetching stars for user: {user.login}...")

    starred_repos = user.get_starred()

    # 4. å¢é‡æ›´æ–°é€»è¾‘
    new_cache = {}

    for repo in tqdm(starred_repos, total=starred_repos.totalCount):
        repo_id = str(repo.id)

        # å¦‚æœç¼“å­˜é‡Œæœ‰ï¼Œä¸”ä¸æ˜¯ Uncategorizedï¼Œç›´æ¥å¤ç”¨
        if repo_id in cache and cache[repo_id].get('category') != 'Uncategorized':
            cache[repo_id]['stars'] = repo.stargazers_count
            cache[repo_id]['language'] = repo.language
            new_cache[repo_id] = cache[repo_id]
        else:
            # æ–°ä»“åº“æˆ–éœ€è¦é‡æ–°åˆ†ç±»
            print(f"ğŸ¤– Classifying: {repo.full_name}")

            # è·å– Topics
            try:
                topics = repo.get_topics()
            except Exception:
                topics = []

            result = get_llm_classification(
                repo.name,
                repo.description or "",
                topics,
                categories
            )

            category_name = result.get("category", "Uncategorized")

            # --- åŠ¨æ€æ‰©å±•é€»è¾‘ ---
            if category_name not in categories and "(" in category_name:
                print(f"âœ¨ å‘ç°æ–°é¢†åŸŸï¼Œè‡ªåŠ¨æ‰©å±•åˆ†ç±»ä½“ç³»: {category_name}")
                categories.append(category_name)
                save_categories(categories)

            entry = {
                "name": repo.full_name,
                "url": repo.html_url,
                "description": repo.description,
                "stars": repo.stargazers_count,
                "category": category_name,
                "language": repo.language,
                "topics": topics,
                "confidence": result.get("confidence", "unknown"),
                "reasoning": result.get("reasoning", ""),
                "crawled_at": time.time()
            }
            new_cache[repo_id] = entry
            time.sleep(1)  # é¿å… LLM Rate Limit

    # 5. ä¿å­˜ç¼“å­˜
    with open(CACHE_FILE, 'w', encoding='utf-8') as f:
        json.dump(new_cache, f, ensure_ascii=False, indent=2)

    # 6. ä¿å­˜åˆ†ç±»ä½“ç³»
    save_categories(categories)

    # 7. ç”Ÿæˆ README
    update_readme(new_cache, categories)
    print("Done!")


if __name__ == "__main__":
    main()
