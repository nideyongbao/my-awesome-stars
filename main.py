import os
import json
import time
import github
from github import Github
from openai import OpenAI
from tqdm import tqdm

# --- é…ç½®éƒ¨åˆ† ---
GITHUB_TOKEN = os.getenv("GH_TOKEN")
LLM_API_KEY = os.getenv("LLM_API_KEY")
LLM_BASE_URL = os.getenv("LLM_BASE_URL", "https://api.deepseek.com")
LLM_MODEL = os.getenv("LLM_MODEL", "deepseek-chat")

# é…ç½®æ–‡ä»¶è·¯å¾„
CACHE_FILE = "stars_cache.json"
CATEGORY_FILE = "categories.json"

# --- Prompt æ¨¡æ¿ (JSON è¾“å‡º + æ€ç»´é“¾) ---
PROMPT_TEMPLATE = """
ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„è½¯ä»¶å·¥ç¨‹å¸ˆå’Œå¼€æºç¤¾åŒºä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°† GitHub ä»“åº“ç²¾å‡†åˆ†ç±»åˆ°æœ€åŒ¹é…çš„ç±»åˆ«ã€‚

### è¾“å…¥ä¿¡æ¯
- ä»“åº“å: {repo_name}
- æè¿°: {description}
- Topics: {topics}

### é¢„è®¾åˆ†ç±»ä½“ç³»
{categories_json}

### æ ¸å¿ƒå†³ç­–é€»è¾‘ (Priority Logic)

1. **é¦–å…ˆåˆ¤æ–­æ˜¯å¦æ˜¯ AI ç›¸å…³é¡¹ç›®**ï¼š
   - å¦‚æœæè¿°æˆ– Topics ä¸­åŒ…å« LLMã€MLã€AIã€æ¨¡å‹ã€è®­ç»ƒã€æ¨ç†ç­‰å…³é”®è¯ â†’ è¿›å…¥ AI åˆ†ç±»å†³ç­–
   - å¦‚æœä¸åŒ…å« â†’ ç›´æ¥ä½¿ç”¨ `Dev-`ã€`Tools-`ã€`CS-Education` ç­‰é€šç”¨åˆ†ç±»

2. **AI System ç»†åˆ†åŸåˆ™**ï¼š
   - **Posttraining vs FineTuning**: å¦‚æœæ˜¯å…¨é‡è®­ç»ƒæ¡†æ¶é€‰ `AI-Sys-Posttraining`ï¼›å¦‚æœæ˜¯ LoRA/QLoRA ç­‰è½»é‡å¾®è°ƒåº“ï¼ˆå¦‚ PEFTï¼‰é€‰ `AI-Sys-FineTuning`ã€‚
   - **Compiler vs Kernel**: å¦‚æœæ˜¯ç«¯åˆ°ç«¯çš„ç¼–è¯‘å™¨ï¼ˆå¦‚ TVMï¼‰é€‰ `AI-Sys-Compiler`ï¼›å¦‚æœæ˜¯å…·ä½“çš„ç®—å­å®ç°ï¼ˆå¦‚ FlashAttentionï¼‰é€‰ `AI-Sys-Kernel`ã€‚
   - **Ops vs Cluster**: å¦‚æœæ˜¯ K8s/Ray/Slurm ç›¸å…³çš„è°ƒåº¦é€‰ `AI-Sys-Cluster`ï¼›å¦‚æœæ˜¯ WandB ç­‰æŒ‡æ ‡ç›‘æ§é€‰ `AI-Sys-MLOps`ã€‚

3. **AI Data ç»†åˆ†åŸåˆ™**ï¼š
   - **Vector vs RAG**: å¦‚æœæ˜¯å•çº¯çš„å‘é‡æ•°æ®åº“ï¼ˆå¦‚ Milvusï¼‰é€‰ `AI-Data-Vector`ï¼›å¦‚æœæ˜¯æ„å»º RAG åº”ç”¨çš„ç¼–æ’æ¡†æ¶ï¼ˆå¦‚ LangChainï¼‰é€‰ `AI-App-RAG`ã€‚
   - **Synthetic**: å‡¡æ˜¯æ¶‰åŠ "Synthetic Data" æˆ– "Distillation" çš„å·¥å…·ï¼Œä¼˜å…ˆé€‰ `AI-Data-Synthetic`ã€‚

4. **MCP ç‰¹åˆ«è§„åˆ™**:
   - å‡¡æ˜¯æåŠ "Model Context Protocol" æˆ– "MCP Server" çš„é¡¹ç›®ï¼Œå¿…é¡»å½’å…¥ `AI-App-MCP`ã€‚

5. **é€šç”¨å¼€å‘é¡¹ç›®åˆ†ç±»**:
   - **Web æ¡†æ¶/å‰ç«¯/åç«¯**: `Dev-Web-FullStack`
   - **å®¹å™¨/K8s/äº‘å¹³å°**: `Dev-Infra-Cloud`
   - **æ•°æ®åº“/ç¼“å­˜/å­˜å‚¨**: `Dev-DB-Storage`
   - **ç¼–ç¨‹è¯­è¨€å­¦ä¹ èµ„æº**: `Dev-Lang-Core`
   - **å®‰å…¨/æ¸—é€/é€†å‘**: `Dev-Sec`
   - **ç»ˆç«¯å·¥å…·/æ•ˆç‡**: `Tools-Efficiency`
   - **éŸ³è§†é¢‘å¤„ç†å·¥å…·**: `Tools-Media`
   - **æ•™ç¨‹/é¢è¯•/å­¦ä¹ è·¯çº¿**: `CS-Education`
   - **è®ºæ–‡å¤ç°**: `Research-Paper`

6. **å…œåº•è§„åˆ™**:
   - å¦‚æœæ— æ³•ç¡®å®šåˆ†ç±»ï¼Œé€‰æ‹© `Uncategorized (æ— æ³•åˆ†ç±»)`

### è¾“å‡ºæ ¼å¼ (JSON)
{{
    "category": "Selected Category Name",
    "reasoning": "ç®€çŸ­ç†ç”±"
}}
"""


def load_categories():
    """ä» categories.json åŠ è½½åˆ†ç±»ä½“ç³»"""
    if not os.path.exists(CATEGORY_FILE):
        raise FileNotFoundError(f"åˆ†ç±»é…ç½®æ–‡ä»¶ {CATEGORY_FILE} ä¸å­˜åœ¨ï¼Œè¯·å…ˆåˆ›å»ºï¼")
    with open(CATEGORY_FILE, 'r', encoding='utf-8') as f:
        return json.load(f)


def save_categories(categories):
    """ä¿å­˜åˆ†ç±»ä½“ç³»ï¼ˆåŒ…å«åŠ¨æ€æ‰©å±•çš„æ–°åˆ†ç±»ï¼‰"""
    with open(CATEGORY_FILE, 'w', encoding='utf-8') as f:
        json.dump(categories, f, ensure_ascii=False, indent=2)


def get_llm_classification(repo_name, description, topics, current_categories):
    """è°ƒç”¨ LLM è¿›è¡Œåˆ†ç±»ï¼Œè¿”å› JSON ç»“æœ"""
    client = OpenAI(api_key=LLM_API_KEY, base_url=LLM_BASE_URL)
    default_result = {"category": "Uncategorized", "confidence": "low", "reasoning": "API Error or Invalid Response"}

    prompt = PROMPT_TEMPLATE.format(
        repo_name=repo_name,
        description=description,
        topics=", ".join(topics) if topics else "N/A",
        categories_json=json.dumps(current_categories, ensure_ascii=False, indent=2)
    )

    try:
        response = client.chat.completions.create(
            model=LLM_MODEL,
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"},  # å¼ºåˆ¶ JSON æ¨¡å¼
            temperature=0.1
        )
        
        # è°ƒè¯•æ—¥å¿—ï¼šæ‰“å°å®Œæ•´å“åº”ç»“æ„
        print(f"ğŸ“¡ API Response for {repo_name}:")
        print(f"   - Model: {LLM_MODEL}")
        print(f"   - Choices count: {len(response.choices) if response.choices else 0}")
        if response.choices:
            print(f"   - Finish reason: {response.choices[0].finish_reason}")
        
        # æ ¡éªŒ response ç»“æ„
        if not response.choices:
            print(f"LLM Error: Empty choices for {repo_name}")
            return default_result
        
        content = response.choices[0].message.content
        print(f"ğŸ“ LLM Raw Response for {repo_name}: {content[:200] if content else 'None'}...")  # è°ƒè¯•æ—¥å¿—
        
        if not content:
            print(f"LLM Error: Empty content for {repo_name}")
            return default_result
        
        result = json.loads(content)
        print(f"âœ… Parsed Result: category={result.get('category', 'N/A')}, reasoning={result.get('reasoning', 'N/A')[:50]}...")
        
        # æ ¡éªŒ result æ˜¯å¦ä¸ºæœ‰æ•ˆ dict ä¸”åŒ…å« category å­—æ®µ
        if not isinstance(result, dict):
            print(f"LLM Error: Result is not a dict for {repo_name}, got: {type(result)}")
            return default_result
        
        if "category" not in result:
            print(f"LLM Warning: Missing 'category' key for {repo_name}, using Uncategorized")
            result["category"] = "Uncategorized"
        
        return result
    except Exception as e:
        if "429" in str(e):
            print(f"âš ï¸ LLM Rate Limit hit for {repo_name}. Sleeping for 60s...")
            time.sleep(60)
            return get_llm_classification(repo_name, description, topics, current_categories)  # é‡è¯•
        else:
            print(f"LLM Error: {e}")
        return default_result


def update_readme(data, categories):
    """ç”Ÿæˆ README.md"""
    # åŠ¨æ€æ”¶é›†æ‰€æœ‰åˆ†ç±»
    all_categories = set()
    for repo in data.values():
        all_categories.add(repo['category'])

    # æ’åºï¼šä¼˜å…ˆ categories åˆ—è¡¨é¡ºåºï¼Œæ–°åˆ†ç±»æŒ‰å­—æ¯åºï¼ŒUncategorized æœ€å
    sorted_cats = []
    seen = set()

    for cat in categories:
        if cat in all_categories:
            sorted_cats.append(cat)
            seen.add(cat)

    remaining = [c for c in all_categories if c not in seen and c != "Uncategorized"]
    remaining.sort()
    sorted_cats.extend(remaining)

    if "Uncategorized" in all_categories:
        sorted_cats.append("Uncategorized")

    # åˆ†ç»„
    grouped = {cat: [] for cat in sorted_cats}
    for repo in data.values():
        cat = repo['category']
        if cat in grouped:
            grouped[cat].append(repo)
        else:
            if "Uncategorized" not in grouped:
                grouped["Uncategorized"] = []
            grouped["Uncategorized"].append(repo)

    # ç”Ÿæˆå†…å®¹
    md = "# ğŸŒŸ My Awesome AI Stars\n\n> ğŸ¤– è‡ªåŠ¨ç”Ÿæˆäº GitHub Actions, Powered by LLM.\n\n"
    md += "## ç›®å½•\n"
    for cat in sorted_cats:
        cat_key = cat.split(" ")[0]
        if " " not in cat:
            cat_key = cat
        count = len(grouped[cat])
        md += f"- [{cat} ({count})](#{cat_key.lower()})\n"

    md += "\n---\n"

    for cat in sorted_cats:
        repos = grouped[cat]
        if not repos:
            continue

        cat_key = cat.split(" ")[0]
        if " " not in cat:
            cat_key = cat

        md += f"## <span id='{cat_key.lower()}'>{cat}</span>\n\n"
        md += "| Project | Description | Stars | Language |\n"
        md += "|---|---|---|---|\n"
        repos.sort(key=lambda x: x['stars'], reverse=True)
        for r in repos:
            desc = (r.get('description') or "").replace("|", r"\|").replace("\n", " ")
            lang = r.get('language') or "N/A"
            md += f"| [{r['name']}]({r['url']}) | {desc[:100]} | {r['stars']} | {lang} |\n"
        md += "\n"

    with open("README.md", "w", encoding="utf-8") as f:
        f.write(md)


def main():
    # 1. åŠ è½½åˆ†ç±»ä½“ç³»
    categories = load_categories()

    # 2. è¯»å–ç¼“å­˜
    if os.path.exists(CACHE_FILE):
        with open(CACHE_FILE, 'r', encoding='utf-8') as f:
            cache = json.load(f)
    else:
        cache = {}

    # 3. è·å– GitHub Stars (ä½¿ç”¨æ–°ç‰ˆ Auth)
    auth = github.Auth.Token(GITHUB_TOKEN)
    g = Github(auth=auth)
    user = g.get_user()
    print(f"Fetching stars for user: {user.login}...")

    starred_repos = user.get_starred()

    # 4. å¢é‡æ›´æ–°é€»è¾‘
    new_cache = {}

    for repo in tqdm(starred_repos, total=starred_repos.totalCount):
        repo_id = str(repo.id)

        # å¦‚æœç¼“å­˜é‡Œæœ‰ï¼Œä¸”ä¸æ˜¯ Uncategorizedï¼Œç›´æ¥å¤ç”¨
        if repo_id in cache and cache[repo_id].get('category') != 'Uncategorized':
            cache[repo_id]['stars'] = repo.stargazers_count
            cache[repo_id]['language'] = repo.language
            new_cache[repo_id] = cache[repo_id]
        else:
            # æ–°ä»“åº“æˆ–éœ€è¦é‡æ–°åˆ†ç±»
            print(f"ğŸ¤– Classifying: {repo.full_name}")

            # è·å– Topics
            try:
                topics = repo.get_topics()
            except Exception:
                topics = []

            result = get_llm_classification(
                repo.name,
                repo.description or "",
                topics,
                categories
            )

            category_name = result.get("category", "Uncategorized")

            # --- åŠ¨æ€æ‰©å±•é€»è¾‘ ---
            if category_name not in categories and "(" in category_name:
                print(f"âœ¨ å‘ç°æ–°é¢†åŸŸï¼Œè‡ªåŠ¨æ‰©å±•åˆ†ç±»ä½“ç³»: {category_name}")
                categories.append(category_name)
                save_categories(categories)

            entry = {
                "name": repo.full_name,
                "url": repo.html_url,
                "description": repo.description,
                "stars": repo.stargazers_count,
                "category": category_name,
                "language": repo.language,
                "topics": topics,
                "confidence": result.get("confidence", "unknown"),
                "reasoning": result.get("reasoning", ""),
                "crawled_at": time.time()
            }
            new_cache[repo_id] = entry
            time.sleep(1)  # é¿å… LLM Rate Limit

    # 5. ä¿å­˜ç¼“å­˜
    with open(CACHE_FILE, 'w', encoding='utf-8') as f:
        json.dump(new_cache, f, ensure_ascii=False, indent=2)

    # 6. ä¿å­˜åˆ†ç±»ä½“ç³»
    save_categories(categories)

    # 7. ç”Ÿæˆ README
    update_readme(new_cache, categories)
    print("Done!")


if __name__ == "__main__":
    main()
